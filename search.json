[{"path":"https://davidhope.ca/BASSr/CODE_DESIGN.html","id":null,"dir":"","previous_headings":"","what":"Code Design","title":"Code Design","text":"file contains notes code design conventions aim making collaboration future modifications easier.","code":""},{"path":"https://davidhope.ca/BASSr/CODE_DESIGN.html","id":"naming","dir":"","previous_headings":"","what":"Naming","title":"Code Design","text":"Snake case used wherever possible Test files named test-XX_DESCRIPTION.R, XX order run (try test lower order functions first).","code":""},{"path":"https://davidhope.ca/BASSr/CODE_DESIGN.html","id":"code-formating","dir":"","previous_headings":"","what":"Code formating","title":"Code Design","text":"Put closing brackets ) next line multi-line functions","code":""},{"path":"https://davidhope.ca/BASSr/CODE_DESIGN.html","id":"best-practices","dir":"","previous_headings":"","what":"Best practices","title":"Code Design","text":"use return() unless calling high function","code":""},{"path":"https://davidhope.ca/BASSr/CODE_DESIGN.html","id":"tidyeval","dir":"","previous_headings":"","what":"tidyeval","title":"Code Design","text":"Use {{ }} tidyeval variable used directly unclear reasons, check_column() function calls main function moved sub check_XXX() function","code":""},{"path":"https://davidhope.ca/BASSr/CODE_DESIGN.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Code Design","text":"see rOxygen article: https://roxygen2.r-lib.org/articles/reuse.html#inheriting-documentation see R/aa_common_docs.R common descriptions stored","code":""},{"path":"https://davidhope.ca/BASSr/CODE_DESIGN.html","id":"other","dir":"","previous_headings":"","what":"Other","title":"Code Design","text":"purrr::map() passing ... must use base R anonymous function \\(x) lambda notation ~. lambda notaion passes mapped variable ... .x ..1, global ... overwritten. R base \\(x) passes x .","code":""},{"path":"https://davidhope.ca/BASSr/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://davidhope.ca/BASSr/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://davidhope.ca/BASSr/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://davidhope.ca/BASSr/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://davidhope.ca/BASSr/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://davidhope.ca/BASSr/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://davidhope.ca/BASSr/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://davidhope.ca/BASSr/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://davidhope.ca/BASSr/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://davidhope.ca/BASSr/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://davidhope.ca/BASSr/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://davidhope.ca/BASSr/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://davidhope.ca/BASSr/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://davidhope.ca/BASSr/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://davidhope.ca/BASSr/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://davidhope.ca/BASSr/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://davidhope.ca/BASSr/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://davidhope.ca/BASSr/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://davidhope.ca/BASSr/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://davidhope.ca/BASSr/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://davidhope.ca/BASSr/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://davidhope.ca/BASSr/articles/BASS_Benefit_Step_by_Step.html","id":"benefit-definition","dir":"Articles","previous_headings":"","what":"Benefit definition","title":"Step by Step","text":"process calculating benefit can defined : 1 .Calculate percentage land cover type : . Study area (pSAp_{SA}) b. Hypothetical sample set (pHSSp_{HSS}) c. Hypothetical sample set plus focal sample unit (pHSS*p_{HSS}^*) 2.Calculate difference Study area sample sets: . ΔHSS=pSA−pHSS{\\Delta HSS} = {p_{SA}} - {p_{HSS}} ΔHSS*=pSA−pHSS*{\\Delta HSS^*} = {p_{SA}} - {p_{HSS}^*} Calculate benefit land cover type ii sample unit jj given hypothetical sample set HH : βHij={|pHSS−pHSS*|,sgn(ΔHSS)=sgn(ΔHSS*)0,sgn(ΔHSS)≠sgn(ΔHSS*)     \\beta_{Hij} =   \\begin{cases}     | p_{HSS} - p_{HSS}^*| ,& \\text{} sgn(\\Delta HSS) = sgn(\\Delta HSS^*) \\\\     0,& \\text{} sgn(\\Delta HSS) \\neq sgn(\\Delta HSS^*)   \\end{cases} consider proportion land cover type value interest: : difference value study area value hypothetical sample set difference value study area value hypothetical sample set plus focal sample unit either positive negative : benefit land cover type : difference value hypothetical sample set value hypothetical sample set plus focal sample unit. otherwise: benefit 0.","code":""},{"path":"https://davidhope.ca/BASSr/articles/BASS_Benefit_Step_by_Step.html","id":"example-work-through","dir":"Articles","previous_headings":"","what":"Example work through","title":"Step by Step","text":"example calculate benefit one sample unit study area. approach applies sample unit hexagons study area also calculating benefits study area hexagons region.","code":""},{"path":"https://davidhope.ca/BASSr/articles/BASS_Benefit_Step_by_Step.html","id":"step-1---load-in-data","dir":"Articles","previous_headings":"","what":"Step 1 - Load in data","title":"Step by Step","text":"need simple features (package sf) layer hexagons study areas sample units. Code create hexagons available Hexagon Creation vignette. first step create load study area sample units. data vignette included package. load BASSr package. ’ll need objects ontario, clrfile, lcc2015_codes, all_study_areas, StudyArea_hexes. Documentation objects found using help function (eg ?BASSr::ontario). raster example study area can found system data (see chunk raster-plot ). Figure 1. Map Ontario study areas example study area shown red sample unit focus single sample unit within study area, shown red. call ‘focal sample unit’. Figure 2. Example sample unit hexagon (red). Used focal sample unit next steps.","code":"study_area_id <- \"ONT_SA_0740\"  SA_sum <- StudyArea_hexes$landcover %>%   as_tibble() %>%   summarize_at(.vars = vars(contains(\"LC\")), .funs = sum) %>%   pivot_longer(cols = contains(\"LC\"), names_to = \"lc\", values_to = \"pHab_SA\") %>%   mutate(pHab_SA = pHab_SA / sum(pHab_SA)) %>%   arrange(pHab_SA) %>%   mutate(     cHAb_SA = cumsum(pHab_SA),     lcFac = forcats::fct_reorder(lc, pHab_SA),     lc_n = as.numeric(stringr::str_extract(lc, \"\\\\d\\\\d\"))   ) %>%   left_join(lcc2015_codes, by = c(\"lc_n\" = \"LCC_CODE\")) %>%   mutate(lcc_fac = forcats::fct_reorder(LCC_NAME, pHab_SA))  set.seed(2277) exampleHex <- slice_sample(StudyArea_hexes$landcover, n = 1)  hex_LC <-   StudyArea_hexes$landcover %>%   as_tibble() %>%   dplyr::select(-geometry) %>%   pivot_longer(cols = contains(\"LC\"), names_to = \"lc\", values_to = \"pHab\") %>%   left_join(SA_sum, by = c(\"lc\")) %>%   arrange(SampleUnitID, pHab_SA) %>%   group_by(SampleUnitID) %>%   mutate(cpHab = cumsum(pHab / 100)) %>%   ungroup() %>%   mutate(lc_n = as.numeric(stringr::str_extract(lc, \"\\\\d\\\\d\")))  exLC <- hex_LC %>% filter(SampleUnitID %in% exampleHex$SampleUnitID) ggplot(all_study_areas) +   geom_sf(data = ontario) +   geom_sf(fill = \"white\") +   theme_linedraw() +   geom_sf(data = filter(all_study_areas, StudyAreaID == study_area_id), fill = \"red\") ggplot(exampleHex) +   geom_sf(fill = \"red\") +   geom_sf(data = StudyArea_hexes$landcover, fill = NA) +   theme_minimal()"},{"path":"https://davidhope.ca/BASSr/articles/BASS_Benefit_Step_by_Step.html","id":"step-2-calculate-habitat-composition","dir":"Articles","previous_headings":"","what":"Step 2 Calculate Habitat Composition","title":"Step by Step","text":"example study area shown . habitat shown National Land Cover Classification 2015. study area 1003 sample unit hexagons 1e+06m2m^2. Figure 3. distribution land cover classes across example study area. Overall, study area primarily classified “Sub-polar polar grassland-lichen-moss” “Wetland”, however n_distinct(exLC$lc) classes study area. Figure 4. distribution National Land Cover Classes within example Study Area variation composition land cover classes among sample units. examine increasing cumulative proportion sample unit hexagon covered given land cover type, see lot variation distribution 1003 hexagons. focal sample unit shown red . Figure 5. cumulative proportion land cover classes within sample hexagons (grey) study area (black). red line shows example hexagon used initial benefit calculation.","code":"r <- terra::rast(system.file(\"extdata\", glue(\"{study_area_id}.tif\"),   package = \"BASSr\", mustWork = T )) %>%   terra::as.data.frame(xy = T) %>%   as_tibble() %>%   filter(!is.na({{study_area_id}})) %>%   left_join(lcc2015_codes, by = join_by({{study_area_id}} == LCC_CODE))   pal_ <- clrfile$rgb names(pal_) <- (clrfile$LCC_NAME) pal_ <- pal_[!is.na(names(pal_))]   lc <- ggplot() +   geom_raster(data = r, aes(x, y, fill = LCC_NAME)) +   ggplot2::scale_discrete_manual(aesthetics = \"fill\", values = pal_) +   geom_sf(data = StudyArea_hexes$landcover, fill = NA) +   labs(x = \"\", y = \"\", fill = \"LCC2015\") +   theme_linedraw()   lc exLC %>%   dplyr::select(lcc_fac, pHab_SA) %>%   mutate(pHab_SA = pHab_SA * 100) %>%   pivot_longer(names_to = \"sampletype_s\", values_to = \"phabitat\", cols = c(\"pHab_SA\")) %>%   mutate(sampletype = ifelse(sampletype_s == \"pHab\", \"Example Sample Unit\", \"Study Area\")) %>%   ggplot(aes(sampletype, phabitat, fill = lcc_fac)) +   geom_bar(stat = \"identity\", position = \"dodge\") +   labs(x = \"\", y = \"Percentage of total\", fill = \"Land Cover\") +   theme_minimal() +   scale_fill_manual(values = pal_) ggplot(hex_LC, aes(lcc_fac, cpHab, group = SampleUnitID)) +   geom_step(     colour = \"grey\",     alpha = 0.1   ) +   geom_step(     data = exLC,     colour = \"red\"   ) +   geom_step(     data = SA_sum,     aes(y = cHAb_SA, group = 1),     colour = \"black\", linewidth = 2   ) +   theme_minimal() +   labs(x = \"Land Cover Class (Increasing freq from left to right)\", y = \"Cumulative proportion of hexagon\") +   theme(axis.text.x = element_text(     family = \"mono\",     angle = 75, vjust = 1, hjust = 1   ))"},{"path":[]},{"path":"https://davidhope.ca/BASSr/articles/BASS_Benefit_Step_by_Step.html","id":"a----select-a-sample-unit-to-calculate-benefit-for","dir":"Articles","previous_headings":"Step 3 Sample unit hexagons - benefit calculation","what":"A. - Select a sample unit to calculate benefit for","title":"Step by Step","text":"Lets focus one sample unit hexagon now. shown Figure 2 5 land cover (Figure 6). mentioned , call focal sample unit now. Figure 6. Example sample unit hexagon (outline). Used focal sample unit next steps. See Figure 3 legend. focal sample unit varies many ways study area. compare ‘focal sample unit’ proportion “Sub-polar polar grassland-lichen-moss” found throughout study area can see focal sample unit much lower percentage study area.    table compares percentages land cover types differs example sample unit study area. example, focal sample unit large proportion “Temperate sub-polar shrubland” relative study area, percentage “Sub-polar polar grassland-lichen-moss” much lower study area. differences study area form backbone benefit calculation focal sample unit.","code":"r2 <- r %>% filter(x < st_bbox(exampleHex)[[3]] & x > st_bbox(exampleHex)[[1]] & y < st_bbox(exampleHex)[[4]] & y > st_bbox(exampleHex)[[2]]) ggplot() +   geom_raster(data = r2, aes(x, y, fill = LCC_NAME)) +   ggplot2::scale_discrete_manual(aesthetics = \"fill\", values = pal_) +   labs(x = \"\", y = \"\", fill = \"LCC2015\") +   theme_linedraw() +   # ggspatial::annotation_scale(location = \"bl\", width_hint = 0.4)  +   geom_sf(data = exampleHex, fill = NA, colour = \"red\", size = 2) +   theme(legend.position = \"none\") +   coord_sf(xlim = st_bbox(exampleHex)[c(1, 3)], ylim = st_bbox(exampleHex)[c(2, 4)]) exLC %>%   dplyr::select(lcc_fac, pHab, pHab_SA) %>%   mutate(pHab_SA = pHab_SA * 100) %>%   pivot_longer(names_to = \"sampletype_s\", values_to = \"phabitat\", cols = c(\"pHab_SA\", \"pHab\")) %>%   mutate(sampletype = ifelse(sampletype_s == \"pHab\", \"Focal Sample Unit\", \"Study Area\")) %>%   filter(grepl(\"grassland-lichen-moss\", lcc_fac)) %>%   ggplot(aes(sampletype, phabitat, fill = lcc_fac)) +   geom_bar(stat = \"identity\") +   labs(x = \"\", y = \"Percentage of total\", fill = \"Land Cover\", title = exLC$LCC_NAME[grepl(\"grassland-lichen-moss\", exLC$LCC_NAME)]) +   theme_minimal() +   theme(legend.position = \"none\") +   scale_fill_manual(values = pal_) +   lims(y = c(0, 100)) exLC %>%   dplyr::select(lcc_fac, pHab, pHab_SA) %>%   mutate(pHab_SA = pHab_SA * 100) %>%   pivot_longer(names_to = \"sampletype_s\", values_to = \"phabitat\", cols = c(\"pHab_SA\", \"pHab\")) %>%   mutate(sampletype = ifelse(sampletype_s == \"pHab\", \"Focal Sample Unit\", \"Study Area\")) %>%   filter(grepl(\"grassland-lichen-moss|Wetland\", lcc_fac)) %>%   ggplot(aes(sampletype, phabitat, fill = lcc_fac)) +   geom_bar(stat = \"identity\") +   labs(     x = \"\", y = \"Percentage of total\", fill = \"Land Cover\",     title = glue::glue(\"{exLC$LCC_NAME[grepl('grassland-lichen-moss',exLC$LCC_NAME)]} and Wetland\")   ) +   theme_minimal() +   theme(legend.position = \"none\") +   scale_fill_manual(values = pal_) +   lims(y = c(0, 100)) exLC %>%   dplyr::select(lcc_fac, pHab, pHab_SA) %>%   mutate(pHab_SA = pHab_SA * 100) %>%   pivot_longer(names_to = \"sampletype_s\", values_to = \"phabitat\", cols = c(\"pHab_SA\", \"pHab\")) %>%   mutate(sampletype = ifelse(sampletype_s == \"pHab\", \"Focal Sample Unit\", \"Study Area\")) %>%   ggplot(aes(sampletype, phabitat, fill = lcc_fac)) +   geom_bar(stat = \"identity\") +   labs(     x = \"\", y = \"Percentage of total\",     fill = \"Land Cover\"   ) +   theme_minimal() +   scale_fill_manual(values = pal_) exLC %>%   dplyr::select(lcc_fac, pHab, pHab_SA) %>%   mutate(pHab_SA = pHab_SA * 100) %>%   knitr::kable(col.names = c(\"Land Cover\", \"% Example Sample Unit\", \"% Example Study Area\"), digits = 2)"},{"path":"https://davidhope.ca/BASSr/articles/BASS_Benefit_Step_by_Step.html","id":"b----draw-a-hypothetical-sample-set-from-all-sample-units-in-study-area","dir":"Articles","previous_headings":"Step 3 Sample unit hexagons - benefit calculation","what":"B. - Draw a hypothetical sample set from all sample units in study area","title":"Step by Step","text":"examine importance focal sample unit, first draw 1 random, spatially-dispersed sample set comprised 10 sample unit hexagons. 10 randomly drawn sample units defined hypothetical sample set. used estimate focal sample unit increase (decrease) representivity sample set. Figure 5. Plot focal sample unit (red) hypothetical sample set (grey) within study area (hexagons). Hypothetical Sample Set 9.9% less Wetland Study Area 8.1% less Study Area inclusion Focal Sample Unit Therefore Focal Sample Unit makes Sample Set like Study Area Therefore Benefit! Benefit = 0.18 1.8%  Hypothetical Sample Set 2.6% greater shrubland Study Area 5.1% greater Study Area inclusion Focal Sample Unit Therefore Focal Sample Unit makes Sample Set less like Study Area Therefore Benefit Benefit = 0 Figure 6. Distribution land cover focal sample unit, hypothetical sample set, hypothetical sample set plus focal sample unit study area next step compare habitat representivity differs focal sample unit, hypothetical sample set, hypothetical sample set focal sample unit included study area whole. can see hypothetical sample set larger percentage “Sub-polar taiga needleleaf forest” study area, focal sample unit lower percentage study area. focal sample unit added sample set, percentage shifts downwards closer percentage study area. opposite true “Temperate sub-polar shrubland”, adding focal sample unit moves sample set plus focal sample unit away percentage observed study area. fundamental measure representivity focal sample unit.","code":"sample_hexes <- BASSr::draw_random_samples(   land_hex = StudyArea_hexes$landcover,   num_runs = 1, n_samples = 10 ) sample_hexes_sf <- StudyArea_hexes$landcover %>%     dplyr::filter(SampleUnitID %in% sample_hexes$SampleUnitID)  hex_wHHS <-   ggplot(exampleHex) +   geom_sf(fill = \"red\") +   geom_sf(data = StudyArea_hexes$landcover, fill = NA) +   geom_sf(data = sample_hexes_sf, fill = \"grey\") +   theme_minimal()  hex_wHHS sample_hexes_phab <- hex_LC %>%   filter(SampleUnitID %in% sample_hexes_sf$SampleUnitID) %>%   group_by(lcc_fac) %>%   summarize(pHab_samp = sum(pHab)) %>%   ungroup() %>%   mutate(pHab_samp = pHab_samp / sum(pHab_samp) * 100)  m2toha <- 0.0001 study_area_size <- as.numeric(sum(st_area(StudyArea_hexes$landcover))) * m2toha hexsize <- as.numeric(st_area(exampleHex)) * m2toha   samp_com <-   left_join(exLC %>% dplyr::select(lcc_fac, pHab, pHab_SA), sample_hexes_phab) %>%   mutate(     pHab_Sample_plus_hex = 100 * ((pHab * hexsize + pHab_samp * hexsize * 10) /       (sum(pHab * hexsize) + sum(pHab_samp * hexsize * 10))),     pHab_SA = pHab_SA * 100   ) %>%   dplyr::select(lcc_fac, pHab, pHab_samp, pHab_Sample_plus_hex, pHab_SA)  names(samp_com) <- c(\"lcFac\", \"Focal Sample Unit\", \"Hypothetical Sample Set\", \"Sample Set + Sample Unit\", \"Study Area\")   d <-   samp_com %>%   pivot_longer(names_to = \"sampletype\", values_to = \"phabitat\", cols = -lcFac) %>%   mutate(sampletype = factor(sampletype, levels = c(\"Focal Sample Unit\", \"Hypothetical Sample Set\", \"Sample Set + Sample Unit\", \"Study Area\"))) # c(\"Hexagon\",  \"Sample\", \"Sample + Hex\",\"Study Area\"))) plot_single <- function(x) {   d %>%     filter(lcFac == names(pal_[x])) %>%     ggplot(aes(sampletype, phabitat)) +     geom_bar(stat = \"identity\", fill = pal_[x]) +     # scale_fill_viridis_d() +     # scale_fill_manual(values = pal_)+     labs(x = \"\", y = \"Percentage of total\", fill = \"Land Cover\", title = names(pal_[x])) +     geom_text(aes(label = glue::glue(\"{round(phabitat,1)} %\")), position = position_nudge(y = -1)) +     theme_minimal()  } hexplot <- function(fill_) {   ggplot(exampleHex) +     geom_sf(fill = fill_) +     theme(       panel.background = element_blank(),       axis.ticks = element_blank(),       axis.text = element_blank()     ) } hhs_plot <-   ggplot(StudyArea_hexes$landcover) +   geom_sf(fill = NA, colour = \"white\") +   theme_minimal() +   theme(     axis.text = element_blank(), axis.line = element_blank(),     axis.ticks = element_blank()   )   key_row <- (hhs_plot + geom_sf(data = exampleHex, fill = \"red\")) +   hhs_plot + geom_sf(data = sample_hexes_sf) +   (hhs_plot + geom_sf(data = exampleHex, fill = \"red\") + geom_sf(data = sample_hexes_sf)) +   hhs_plot + geom_sf(fill = NA) +   plot_layout(ncol = 4)  # (hex_wHHS + theme(axis.text = element_blank())) /  (plot_single(8) / (key_row)) + plot_layout(heights = c(2, 1)) (plot_single(14) / (key_row)) + plot_layout(heights = c(2, 1)) fullplot <- d %>%   ggplot(aes(sampletype, phabitat, fill = lcFac)) +   geom_bar(stat = \"identity\") +   scale_fill_manual(values = pal_) +   labs(x = \"\", y = \"Percentage of total\", fill = \"Land Cover\") +   theme_minimal()  (fullplot / (key_row)) + plot_layout(heights = c(2, 1)) knitr::kable(samp_com, digits = 2)"},{"path":"https://davidhope.ca/BASSr/articles/BASS_Benefit_Step_by_Step.html","id":"c----calculate-representivity","dir":"Articles","previous_headings":"Step 3 Sample unit hexagons - benefit calculation","what":"C. - Calculate representivity","title":"Step by Step","text":"mentioned , adding focal sample unit sample set, shifts habitat composition slightly focal sample unit quite different sample set. now want see adding sample unit hypothetical sample set make updated sample set representative study area.","code":""},{"path":"https://davidhope.ca/BASSr/articles/BASS_Benefit_Step_by_Step.html","id":"d----calculate-benefit-for-sample-unit","dir":"Articles","previous_headings":"Step 3 Sample unit hexagons - benefit calculation","what":"D. - Calculate benefit for sample unit","title":"Step by Step","text":"calculate benefit focal sample unit, determine land cover class including focal sample unit hypothetical sample set makes sample set less representative. , given land cover class, hypothetical sample set becomes similar study area, benefit difference hypothetical sample set’s representivity (percentage land cover class) representivity sample unit added sample set. Otherwise, benefit land cover class zero. benefit across land cover types summed make benefit value focal sample unit hypothetical sample set. βHj=∑=1i=kβHij\\beta_{Hj} = \\sum_{= 1}^{= k}\\beta_{Hij} table , 5 land cover types benefit (Urban Built-,Temperate sub-polar needleleaf forest, Wetland, Sub-polar polar grasslandlichen-moss, Sub-polar taiga needleleaf forest). mentioned “Temperate sub-polar shrubland” moves hypothetical sample set away study area percentage. However “Sub-polar taiga needleleaf” focal sample unit’s low percentage benefit moves hypothetical sample set percentage lower closer study area’s percent. benefit focal sample unit hypothetical sample unit 0.039. However, sampled 10 sample units hypothetical sample set, may accurate picture benefit focal sample unit.","code":"rep_tabl <- samp_com %>%   # mutate_at(vars(-lcFac), ~(.*study_area_size))   mutate(     `Desired Direction` = case_when(       `Study Area` > `Hypothetical Sample Set` ~ \"Positive\",       `Study Area` < `Hypothetical Sample Set` ~ \"Negative\",       `Study Area` == `Hypothetical Sample Set` ~ \"None\"     ),     `Observed Direction` = case_when(       `Sample Set + Sample Unit` > `Hypothetical Sample Set` ~ \"Positive\",       `Sample Set + Sample Unit` < `Hypothetical Sample Set` ~ \"Negative\",       `Sample Set + Sample Unit` == `Hypothetical Sample Set` ~ \"None\"     ),     `Land Cover Benefit` = case_when(       `Observed Direction` == \"None\" ~ \"No Benefit\",       `Desired Direction` == `Observed Direction` ~ \"Benefit\",       TRUE ~ \"No Benefit\"     ),     benefit = case_when(       `Land Cover Benefit` == \"Benefit\" ~ abs(`Hypothetical Sample Set` - `Sample Set + Sample Unit`) / 100,       TRUE ~ 0     )   ) %>%   mutate(Benefit = ifelse(benefit == 0, \"0\", ifelse(benefit < 0.001, \"<0.001\", as.character(round(benefit, 3)))))   knitr::kable(rep_tabl %>%   dplyr::select(-benefit), digits = 2)"},{"path":"https://davidhope.ca/BASSr/articles/BASS_Benefit_Step_by_Step.html","id":"e--repeat-multiple-times","dir":"Articles","previous_headings":"Step 3 Sample unit hexagons - benefit calculation","what":"E. Repeat multiple times","title":"Step by Step","text":"get useful measure benefit, calculate benefit focal sample unit across 200 randomly drawn hypothetical sample sets. β‾j=∑j=1j=NβHjN\\bar\\beta_{j} =  \\frac{\\sum_{j = 1}^{j = N}\\beta_{Hj}}{N} Figure 7. Example focal sample unit benefit, calculated using 200 randomly drawn hypothetical sample sets. Mean benefit shown vertical dotted line. quite large variation benefit calculated across sample set iterations. final measure benefit focal sample unit 0.059. Now, using 200 hypothetical sample sets used generate Figure 7 example focal sample unit calculate benefit using sample units study area focal sample unit.","code":"# landcover_ha <- StudyArea_hexes$landcover %>% #   mutate_at(.vars = vars(contains(\"LC\")),.funs = ~(.*area)) %>% ungroup # att.long <- BASSr::prepare_hab_long(as_tibble(landcover_ha)) # set.seed(1234) sample_hexes200 <- BASSr::draw_random_samples( # att_cleaned = as_tibble(landcover_ha),   land_hex = StudyArea_hexes$landcover, use_grts = F,   num_runs = 200, n_samples = 10 ) multi_ex <- BASSr::calculate_benefit(   samples = sample_hexes200, #|>   # mutate_at(.vars = vars(contains(\"LC\")),.funs = ~(.*hexsize)) ,   hex_id = SampleUnitID,   land_hex = StudyArea_hexes$landcover ) |>   # exampleHex%>% #as_tibble %>%   # mutate_at(.vars = vars(contains(\"LC\")),.funs = ~(.*hexsize)) ) |>   filter(SampleUnitID == exampleHex$SampleUnitID)   BASSr:::prepare_hab_long(   StudyArea_hexes$landcover |> select(-area)   # mutate_at(.vars = vars(contains(\"LC\")),.funs = ~(.*hexsize)) ) |>   dplyr::select(\"lc\", \"area_total\") %>%   dplyr::distinct() %>%   dplyr::rename(\"area\" = \"area_total\") |>   arrange(lc) #> # A tibble: 13 × 2 #>    lc         area #>    <chr>     <dbl> #>  1 LC01   1469.    #>  2 LC02  10808.    #>  3 LC05    856.    #>  4 LC06    139.    #>  5 LC08   7096.    #>  6 LC10   8603.    #>  7 LC11      0.370 #>  8 LC12  30873.    #>  9 LC13   9823.    #> 10 LC14  20424.    #> 11 LC16   3298.    #> 12 LC17     41.4   #> 13 LC18   6871. SA_sum %>%   mutate(ha = pHab_SA * study_area_size) |>   select(lc, ha) |>   arrange(lc) #> # A tibble: 13 × 2 #>    lc           ha #>    <chr>     <dbl> #>  1 LC01   1469.    #>  2 LC02  10808.    #>  3 LC05    856.    #>  4 LC06    139.    #>  5 LC08   7096.    #>  6 LC10   8603.    #>  7 LC11      0.370 #>  8 LC12  30873.    #>  9 LC13   9823.    #> 10 LC14  20424.    #> 11 LC16   3298.    #> 12 LC17     41.4   #> 13 LC18   6871.   multi_exbroken <- purrr::map_df(   1:200,   ~ BASSr:::quick_ben(     d = exampleHex, # %>% as_tibble %>%     # dplyr::select(-geometry) %>%     # mutate_at(.vars = vars(contains(\"LC\")),     # .funs = ~(.*hexsize)),     samples = sample_hexes200 %>%       st_drop_geometry() |>       filter(run == .x) %>%       summarize_at(.vars = vars(contains(\"LC\")), .funs = ~ sum(.)),     land_cover_summary = SA_sum %>% mutate(area = pHab_SA * study_area_size),     hex_id = SampleUnitID, print = F   ) )   ggplot(multi_exbroken, aes(benefit)) +   geom_density(fill = \"grey\") +   geom_vline(xintercept = multi_ex$benefit, linetype = 2) +   theme_minimal() +   labs(x = \"Benefit of Example Sample Unit\", y = \"Density\") +   # xlim(0, 0.15) +   geom_text(aes(x = multi_ex$benefit + 0.01, y = 1), label = \"bar(beta)[j]\", parse = T)"},{"path":"https://davidhope.ca/BASSr/articles/BASS_Benefit_Step_by_Step.html","id":"f--run-benefit-calculation-for-all-sample-units","dir":"Articles","previous_headings":"Step 3 Sample unit hexagons - benefit calculation","what":"F. Run benefit calculation for all sample units","title":"Step by Step","text":"total benefit example focal sample unit based national land cover shown Figure 7 (0.059). compare values calculated using sample units study area focal sample unit ? start calculating benefit sample unit using hypothetical sample set shown Figure 5.  much variation across sample units within iterations example sample units. example sample unit looks middle possibly bimodal distribution. However calculated distribution across sample units using just one hypothetical sample set comprised 10 sample units. unlikely informative . Figure 7, now use full 200 randomly drawn hypothetical sample sets. goal calculate sample unit’s benefit multiple times many randomly drawn hypothetical sample sets. smaller number sample units given hypothetical sample set, wider distribution benefits likely across sample units study area variance runs. size sample set small iterations numerous. calculated benefit sample unit focal sample unit using 200 randomly drawn sample sets 10 study unit hexagons. key point start hectares (another measure area) land cover dataset rather percent proportion. Othwerwise, benefit calculation incorrectly estimate habitat representivity focal sample unit plus hypothetical sample set. Figure 9. Distribution across sample units study area mean benefit calculated using 200 randomly drawn (replacment; black) hypothetical sample sets 100 hypothetical sample sets (grey), consisting 10 sample units. mean benefit example focal sample unit described shown dotted line Increasing number randomly drawn hypothetical sample sets 100 200 drastically change number . Lets look larger sample set size look like. next calculated mean benefit sample units using 200 hypothetical sample sets 20 samples hypothetical sample set. Figure 10. Distribution mean benefit distribution across sample units. Calculation benefit completed using 200 randomly drawn hypothetical sample sets 20 sample units (grey distribution).compared distribution 200 sample sets 10 sample units (black distribution). mean benefit example hexagon sample sets 20 sample units shown dotted line. Calculating hypothetical sample sets 20 sample units instead 10 shifts benefits given sample unit lower. occurs benefit adding individual sample unit sample set average smaller number units comprising hypothetical sample set plus focal sample unit increases. shape distribution remains roughly example study unit hexagon position distributions.","code":"one_sample <- BASSr:::quick_ben(   d = StudyArea_hexes$landcover,   samples = sample_hexes[1, ] |> st_drop_geometry(),   land_cover_summary = SA_sum %>% mutate(area = pHab_SA * study_area_size),   hex_id = SampleUnitID, print = F )  ggplot(one_sample, aes(benefit)) +   geom_density(fill = \"grey\") +   geom_vline(xintercept = multi_ex$benefit, linetype = 2) +   labs(x = \"Benefit\", y = \"Density\") +   theme_minimal() +   # xlim(0, 0.15)  +   geom_text(aes(x = multi_ex$benefit + 0.01, y = 1.5), label = \"bar(beta)[example]\", parse = T) # set.seed(1234) # sample_hexes2 <- BASSr::draw_random_samples(att_cleaned = as_tibble(landcover_ha), #                                            att.sf = st_centroid(landcover_ha), #                                            num_runs = 200, nsamples = 10)  benefits2 <- BASSr::calculate_benefit(   samples = sample_hexes200, #|>   hex_id = SampleUnitID,   land_hex = StudyArea_hexes$landcover )  sample_hexes100 <- sample_hexes200[sample_hexes200$run <= 100, ] benefits1 <- calculate_benefit(   samples = sample_hexes100, #|>   hex_id = SampleUnitID,   land_hex = StudyArea_hexes$landcover )  ggplot(benefits2, aes(benefit)) +   geom_density(fill = \"black\", alpha = 1) +   geom_density(data = benefits1, fill = \"grey\", alpha = 0.5) +   geom_vline(     xintercept = benefits2$benefit[benefits2$SampleUnitID == exampleHex$SampleUnitID],     linetype = 2   ) +   labs(x = \"Benefit\", y = \"Density\") +   theme_minimal() +   xlim(0, 0.15) set.seed(1234) sample_hexes3 <- BASSr::draw_random_samples(   land_hex = StudyArea_hexes$landcover, use_grts = F,   num_runs = 200, n_samples = 20 )  benefits3 <- calculate_benefit(   samples = sample_hexes3, #|>   hex_id = SampleUnitID,   land_hex = StudyArea_hexes$landcover )  ggplot(benefits3, aes(benefit)) +   geom_density(data = benefits2, fill = \"black\") +   geom_density(fill = \"grey\", alpha = 0.5) +   geom_vline(     xintercept = benefits3$benefit[benefits3$SampleUnitID == exampleHex$SampleUnitID],     linetype = 2   ) +   labs(x = \"Benefit\", y = \"Density\") +   theme_minimal() +   xlim(0, 0.15)"},{"path":"https://davidhope.ca/BASSr/articles/BASS_Benefit_Step_by_Step.html","id":"represent-the-study-area","dir":"Articles","previous_headings":"","what":"Represent the Study Area","title":"Step by Step","text":"running multiple iterations drawing hypothetical sample sets can show benefit adding sample unit draw expected increase representivity final surveyed sample units. Figure 11. plotted mean benefit estimate running 200 iterations hypothetical sample sets 10 sample units.","code":"benefit_sf <-   ggplot(benefits2 |> st_join(x = StudyArea_hexes$landcover)) +   geom_sf(aes(fill = benefit)) +   scale_fill_viridis_c() +   theme_linedraw() +   geom_sf(data = exampleHex, fill = NA, colour = \"red\") #+ # ggspatial::annotation_scale(location = \"bl\", width_hint = 0.4) benefit_sf"},{"path":"https://davidhope.ca/BASSr/articles/BASS_Benefit_Step_by_Step.html","id":"how-the-benefit-calculation-is-used-in-bass","dir":"Articles","previous_headings":"","what":"How the benefit calculation is used in BASS","title":"Step by Step","text":"benefit sample unit calculated subsiquently used cost estimate sample unit calculate selection probability. β\\beta benefit, rescaled 0 1 1 highest benefit study area CC scaled cost (0 1 1 highest cost study area), selection probability pp p=β(1−c) p = \\beta(1-c) selection probabilities used selecting sample units sample within study area using GRTS algorithm.","code":""},{"path":"https://davidhope.ca/BASSr/articles/BASSr.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Getting Started","text":"Get spatial data - Hexagonal grid (primary spatial units - PSU) land cover characteristics hex Get cost data Run full_BASS_run()","code":""},{"path":"https://davidhope.ca/BASSr/articles/BASSr.html","id":"spatial-data","dir":"Articles","previous_headings":"Setup","what":"1. Spatial Data","title":"Getting Started","text":"Columns Cell/Hex ID (e.g., ET_Index, hex_id) Columns defining land cover (e.g., CORINE land cover CLC CLC15_1) must either POINT (MULTI)POLYGON (converted points) Land cover characteristics percentages, XXXX? Clean hex data","code":"psu_hex <- clean_land_cover(psu_hex_dirty,  pattern = \"CLC0013_\") %>%   units::drop_units() # for plotting, get rid of m^2 ## ℹ Renaming land cover columns ## • From: CLC0013_1, CLC0013_2, CLC0013_3, CLC0013_4, CLC0013_5, CLC0013_6 ## • To: LC01, LC02, LC03, LC04, LC05, LC06 ggplot(data = psu_hex, aes(fill = LC01)) +   geom_sf() +   scale_fill_viridis_c()"},{"path":"https://davidhope.ca/BASSr/articles/BASSr.html","id":"basic-run","dir":"Articles","previous_headings":"Setup","what":"Basic Run","title":"Getting Started","text":"","code":"d <- full_BASS_run(land_hex = psu_hex,                     num_runs = 10,                    n_samples = 3) ## ℹ Spatial object land_hex should be POINTs not POLYGONs ## • Don't worry, I'll fix it! ## • Assuming constant attributes and using centroids as points ## ℹ Finished GRTS draw of 10 runs and 3 samples ggplot(data = d, aes(colour = benefit)) +   geom_sf() +   labs(colour = \"Benefit\") +   scale_colour_viridis_c() d_hex <- left_join(psu_hex, st_drop_geometry(d), by = \"hex_id\")  ggplot(data = d_hex, aes(fill = benefit)) +   geom_sf() +   labs(fill = \"Benefit\") +   scale_fill_viridis_c()"},{"path":"https://davidhope.ca/BASSr/articles/BASSr.html","id":"including-costs","dir":"Articles","previous_headings":"Setup","what":"Including Costs","title":"Getting Started","text":"costs highly beneficial points much higher?  Still high inclusion probability, points become relatively ‘better’.","code":"d <- full_BASS_run(land_hex = psu_hex,                     num_runs = 10,                    n_samples = 3,                    costs = psu_costs) ## ℹ Spatial object land_hex should be POINTs not POLYGONs ## • Don't worry, I'll fix it! ## • Assuming constant attributes and using centroids as points ## ℹ Finished GRTS draw of 10 runs and 3 samples d_hex <- left_join(psu_hex, st_drop_geometry(d), by = \"hex_id\")  ggplot(data = d_hex, aes(fill = inclpr)) +   geom_sf() +   labs(fill = \"Inclusion\\nProbability\") +   scale_fill_viridis_c() which.max(d$benefit) ## [1] 26 high_cost <- psu_costs high_cost$RawCost[26] <- high_cost$RawCost[26] * 100  d <- full_BASS_run(land_hex = psu_hex,                     num_runs = 10,                    n_samples = 3,                    costs = high_cost) ## ℹ Spatial object land_hex should be POINTs not POLYGONs ## • Don't worry, I'll fix it! ## • Assuming constant attributes and using centroids as points ## ℹ Finished GRTS draw of 10 runs and 3 samples d_hex <- left_join(psu_hex, st_drop_geometry(d), by = \"hex_id\")  ggplot(data = d_hex, aes(fill = inclpr)) +   geom_sf() +   labs(fill = \"Inclusion\\nProbability\") +   scale_fill_viridis_c()"},{"path":"https://davidhope.ca/BASSr/articles/BASSr.html","id":"runs-by-hand","dir":"Articles","previous_headings":"Setup","what":"Runs by ‘hand’","title":"Getting Started","text":"Alternative pipe","code":"psu_hex <- clean_land_cover(psu_hex_dirty, pattern = \"CLC0013_\") ## ℹ Renaming land cover columns ## • From: CLC0013_1, CLC0013_2, CLC0013_3, CLC0013_4, CLC0013_5, CLC0013_6 ## • To: LC01, LC02, LC03, LC04, LC05, LC06 samples <- draw_random_samples(psu_hex, num_runs = 10, n_samples = 3) ## ℹ Spatial object land_hex should be POINTs not POLYGONs ## • Don't worry, I'll fix it! ## • Assuming constant attributes and using centroids as points ## ℹ Finished GRTS draw of 10 runs and 3 samples benefit <- calculate_benefit(psu_hex, samples) ## ℹ Spatial object land_hex should be POINTs not POLYGONs ## • Don't worry, I'll fix it! ## • Assuming constant attributes and using centroids as points inc_prob <- calculate_inclusion_probs(benefit, costs = psu_costs)  d_hex <- left_join(psu_hex, st_drop_geometry(inc_prob), by = \"hex_id\")  ggplot(data = d_hex, aes(fill = inclpr)) +   geom_sf() +   labs(fill = \"Inclusion\\nProbability\") +   scale_fill_viridis_c() final <- psu_hex_dirty %>%   clean_land_cover(pattern = \"CLC0013_\") %>%   draw_random_samples(num_runs = 10, n_samples = 3) %>%   calculate_benefit(psu_hex, samples = .) %>%   calculate_inclusion_probs(costs = psu_costs) ## ℹ Spatial object land_hex should be POINTs not POLYGONs ## • Don't worry, I'll fix it! ## • Assuming constant attributes and using centroids as points ## ℹ Renaming land cover columns ## • From: CLC0013_1, CLC0013_2, CLC0013_3, CLC0013_4, CLC0013_5, CLC0013_6 ## • To: LC01, LC02, LC03, LC04, LC05, LC06 ## ℹ Spatial object land_hex should be POINTs not POLYGONs ## • Don't worry, I'll fix it! ## • Assuming constant attributes and using centroids as points ## ℹ Finished GRTS draw of 10 runs and 3 samples"},{"path":[]},{"path":"https://davidhope.ca/BASSr/articles/BASSr.html","id":"calculating-costs","dir":"Articles","previous_headings":"","what":"Calculating Costs","title":"Getting Started","text":"Need number ARUs deploy …","code":""},{"path":[]},{"path":"https://davidhope.ca/BASSr/articles/BASSr.html","id":"simple-selection","dir":"Articles","previous_headings":"Selection probabilities","what":"Simple selection","title":"Getting Started","text":"’ll sample 12 sites 20% sample, resulting total 14 sites selected.","code":"g <- ggplot() +    geom_sf(data = psu_hex, fill = \"white\") +   geom_sf(data = final, colour = \"grey70\")  g sel <- run_grts_on_BASS(probs = final,                          num_runs = 1,                          nARUs = 12,                          os = 0.2)  sel_plot <- bind_rows(sel[[\"sites_base\"]],                       sel[[\"sites_over\"]])  g +    geom_sf(data = sel_plot, aes(colour = siteuse), size = 5) +   scale_colour_viridis_d(name = \"Type of\\nsites sampled\", end = 0.7)"},{"path":"https://davidhope.ca/BASSr/articles/BASSr.html","id":"stratified-selection","dir":"Articles","previous_headings":"Selection probabilities","what":"Stratified selection","title":"Getting Started","text":"First let’s create dummy stratification add hexes plotting  Now ’ll define want sample two strata. Let’s assume don’t really care habitat , don’t want sample one much.  can see ’ve sampled much B , samples , makes sense: 0.2 * 2 = 0.4 rounds 0 wanted sample , define specific sample amounts instead.  Alternatively point (especially strata) might easier supply data frame rather series lists.","code":"final <- mutate(final, strat = c(rep(\"A\", 15), rep(\"B\", 18))) psu_hex_strat <- select(final, \"hex_id\", \"strat\") |>    st_drop_geometry() |>   left_join(psu_hex, y = _, by = \"hex_id\")  g <- ggplot() +    geom_sf(data = psu_hex_strat, aes(fill = strat), alpha = 0.4) +   geom_sf(data = final, colour = \"grey70\") g nARUs <- list(\"A\" = 2, \"B\" = 10)  sel <- run_grts_on_BASS(probs = final,                          num_runs = 1,                          stratum_id = strat,                         nARUs = nARUs,                          os = 0.2)  sel_plot <- bind_rows(sel[[\"sites_base\"]],                       sel[[\"sites_over\"]])  g +    geom_sf(data = sel_plot, aes(colour = siteuse), size = 5) +   scale_colour_viridis_d(name = \"Type of\\nsites sampled\", end = 0.7) nARUs <- list(\"A\" = 2, \"B\" = 10) os <- list(\"A\" = 1, \"B\" = 4)  sel <- run_grts_on_BASS(probs = final,                          num_runs = 1,                          stratum_id = strat,                         nARUs = nARUs,                          os = os,                         seed = 123)  sel_plot <- bind_rows(sel[[\"sites_base\"]],                       sel[[\"sites_over\"]])  g +    geom_sf(data = sel_plot, aes(colour = siteuse), size = 5) +   scale_colour_viridis_d(name = \"Type of\\nsites sampled\", end = 0.7) nARUs <- data.frame(n = c(2, 10),                     strat = c(\"A\", \"B\"),                     n_os = c(1, 4))  sel <- run_grts_on_BASS(probs = final,                          num_runs = 1,                          stratum_id = strat,                         nARUs = nARUs,                          seed = 123)  sel_plot <- bind_rows(sel[[\"sites_base\"]],                       sel[[\"sites_over\"]])  g +    geom_sf(data = sel_plot, aes(colour = siteuse), size = 5) +   scale_colour_viridis_d(name = \"Type of\\nsites sampled\", end = 0.7)"},{"path":"https://davidhope.ca/BASSr/articles/BASSr_real.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Getting Started - Some real data","text":"Get spatial data - Hexagonal grid (primary spatial units - PSU) land cover characteristics hex Get cost data Run full_BASS_run()","code":""},{"path":"https://davidhope.ca/BASSr/articles/BASSr_real.html","id":"spatial-data","dir":"Articles","previous_headings":"Setup","what":"1. Spatial Data","title":"Getting Started - Some real data","text":"Columns Cell/Hex ID (e.g., ET_Index, hex_id) Columns defining land cover (e.g., CORINE land cover CLC CLC15_1) must either POINT (MULTI)POLYGON (converted points) Land cover characteristics percentages, XXXX? Clean hex data looking?  landscape look like specifically? (Thinking LC01)","code":"ont_hex <- clean_land_cover(StudyArea_hexes$landcover,  pattern = \"LC\") ## ℹ Renaming land cover columns ## • From: LC02, LC05, LC08, LC10, LC12, LC13, LC14, LC01, LC18, LC06, LC16, LC17, LC11 ## • To: LC02, LC05, LC08, LC10, LC12, LC13, LC14, LC01, LC18, LC06, LC16, LC17, LC11 ggplot() +   geom_sf(data = ontario) +   geom_sf(data = ont_hex) ggplot() +   geom_sf(data = ont_hex, aes(fill = LC01)) +   scale_fill_viridis_c()"},{"path":"https://davidhope.ca/BASSr/articles/BASSr_real.html","id":"basic-run","dir":"Articles","previous_headings":"Setup","what":"Basic Run","title":"Getting Started - Some real data","text":"","code":"d <- full_BASS_run(land_hex = ont_hex,                     num_runs = 10,                    n_samples = 3,                    hex_id = SampleUnitID) ## ℹ Spatial object land_hex should be POINTs not POLYGONs ## • Don't worry, I'll fix it! ## • Assuming constant attributes and using centroids as points ## ℹ Finished GRTS draw of 10 runs and 3 samples ## Warning: ! Values across LC columns sum to 100 or 1,  ## ℹ Check to be sure you have not input inputed percentages into your values. ## ✖ Using percentages will not calculate accurate benefit values. ggplot(data = d, aes(colour = benefit)) +   geom_sf(size = 2) +   labs(colour = \"Benefit\") +   scale_colour_viridis_c() # For pretty plotting d_hex <- left_join(ont_hex, st_drop_geometry(d), by = \"SampleUnitID\")  ggplot(data = d_hex, aes(fill = benefit)) +   geom_sf() +   labs(fill = \"Benefit\") +   scale_fill_viridis_c()"},{"path":"https://davidhope.ca/BASSr/articles/BASSr_real.html","id":"including-costs","dir":"Articles","previous_headings":"Setup","what":"Including Costs","title":"Getting Started - Some real data","text":"Perhaps omit sites water. identified costs data TRUE/FALSEs column INLAKE can omitted using omit_flag argument.  grey hexes omitted. costs highly beneficial point much higher?  great option .","code":"costs <- StudyArea_hexes$cost  d <- full_BASS_run(land_hex = ont_hex,                     num_runs = 10,                    n_samples = 3,                    costs = costs,                    hex_id = SampleUnitID,                    seed = 1234) ## ℹ Spatial object land_hex should be POINTs not POLYGONs ## • Don't worry, I'll fix it! ## • Assuming constant attributes and using centroids as points ## ℹ Finished GRTS draw of 10 runs and 3 samples ## Warning: ! Values across LC columns sum to 100 or 1,  ## ℹ Check to be sure you have not input inputed percentages into your values. ## ✖ Using percentages will not calculate accurate benefit values. d_hex <- left_join(ont_hex, st_drop_geometry(d), by = \"SampleUnitID\")  ggplot(data = d_hex, aes(fill = inclpr)) +   geom_sf() +   labs(fill = \"Inclusion\\nProbability\") +   scale_fill_viridis_c() d <- full_BASS_run(land_hex = ont_hex,                     num_runs = 10,                    n_samples = 3,                    costs = costs,                    hex_id = SampleUnitID,                    omit_flag = INLAKE,                    seed = 1234) ## ℹ Spatial object land_hex should be POINTs not POLYGONs ## • Don't worry, I'll fix it! ## • Assuming constant attributes and using centroids as points ## ℹ Finished GRTS draw of 10 runs and 3 samples ## Warning: ! Values across LC columns sum to 100 or 1,  ## ℹ Check to be sure you have not input inputed percentages into your values. ## ✖ Using percentages will not calculate accurate benefit values. d_hex <- left_join(ont_hex, st_drop_geometry(d), by = \"SampleUnitID\")  ggplot(data = d_hex, aes(fill = inclpr)) +   geom_sf() +   labs(fill = \"Inclusion\\nProbability\") +   scale_fill_viridis_c() which.max(d$inclpr) ## [1] 599 high_cost <- costs high_cost$RawCost[559] <- high_cost$RawCost[559] * 100  d <- full_BASS_run(land_hex = ont_hex,                     num_runs = 10,                    n_samples = 3,                    costs = high_cost,                    hex_id = SampleUnitID) ## ℹ Spatial object land_hex should be POINTs not POLYGONs ## • Don't worry, I'll fix it! ## • Assuming constant attributes and using centroids as points ## ℹ Finished GRTS draw of 10 runs and 3 samples ## Warning: ! Values across LC columns sum to 100 or 1,  ## ℹ Check to be sure you have not input inputed percentages into your values. ## ✖ Using percentages will not calculate accurate benefit values. d_hex <- left_join(ont_hex, st_drop_geometry(d), by = \"SampleUnitID\")  ggplot(data = d_hex, aes(fill = inclpr)) +   geom_sf() +   labs(fill = \"Inclusion\\nProbability\") +   scale_fill_viridis_c()"},{"path":"https://davidhope.ca/BASSr/articles/BASSr_real.html","id":"runs-by-hand","dir":"Articles","previous_headings":"Setup","what":"Runs by ‘hand’","title":"Getting Started - Some real data","text":"Alternative pipe","code":"on_hex <- clean_land_cover(StudyArea_hexes$landcover,  pattern = \"LC\") ## ℹ Renaming land cover columns ## • From: LC02, LC05, LC08, LC10, LC12, LC13, LC14, LC01, LC18, LC06, LC16, LC17, LC11 ## • To: LC02, LC05, LC08, LC10, LC12, LC13, LC14, LC01, LC18, LC06, LC16, LC17, LC11 samples <- draw_random_samples(on_hex, num_runs = 10, n_samples = 3,                                seed = 1234) ## ℹ Spatial object land_hex should be POINTs not POLYGONs ## • Don't worry, I'll fix it! ## • Assuming constant attributes and using centroids as points ## ℹ Finished GRTS draw of 10 runs and 3 samples benefit <- calculate_benefit(on_hex, samples, hex_id = SampleUnitID) ## ℹ Spatial object land_hex should be POINTs not POLYGONs ## • Don't worry, I'll fix it! ## • Assuming constant attributes and using centroids as points ## Warning: ! Values across LC columns sum to 100 or 1,  ## ℹ Check to be sure you have not input inputed percentages into your values. ## ✖ Using percentages will not calculate accurate benefit values. inc_prob <- calculate_inclusion_probs(benefit,                                        costs = costs,                                        hex_id = SampleUnitID)  d_hex <- left_join(on_hex, st_drop_geometry(inc_prob), by = \"SampleUnitID\")  ggplot(data = d_hex, aes(fill = inclpr)) +   geom_sf() +   labs(fill = \"Inclusion\\nProbability\") +   scale_fill_viridis_c() ont_hex <- clean_land_cover(StudyArea_hexes$landcover, pattern = \"LC\") ## ℹ Renaming land cover columns ## • From: LC02, LC05, LC08, LC10, LC12, LC13, LC14, LC01, LC18, LC06, LC16, LC17, LC11 ## • To: LC02, LC05, LC08, LC10, LC12, LC13, LC14, LC01, LC18, LC06, LC16, LC17, LC11 final <- ont_hex |>   draw_random_samples(num_runs = 10, n_samples = 3) %>%   calculate_benefit(ont_hex, samples = ., hex_id = SampleUnitID) %>%   calculate_inclusion_probs(costs = costs, hex_id = SampleUnitID) ## ℹ Spatial object land_hex should be POINTs not POLYGONs ## • Don't worry, I'll fix it! ## • Assuming constant attributes and using centroids as points ## ℹ Spatial object land_hex should be POINTs not POLYGONs ## • Don't worry, I'll fix it! ## • Assuming constant attributes and using centroids as points ## ℹ Finished GRTS draw of 10 runs and 3 samples ## Warning: ! Values across LC columns sum to 100 or 1,  ## ℹ Check to be sure you have not input inputed percentages into your values. ## ✖ Using percentages will not calculate accurate benefit values."},{"path":[]},{"path":"https://davidhope.ca/BASSr/articles/BASSr_real.html","id":"calculating-costs","dir":"Articles","previous_headings":"","what":"Calculating Costs","title":"Getting Started - Some real data","text":"Need number ARUs deploy …","code":""},{"path":[]},{"path":"https://davidhope.ca/BASSr/articles/BASSr_real.html","id":"simple-selection","dir":"Articles","previous_headings":"Selection probabilities","what":"Simple selection","title":"Getting Started - Some real data","text":"’ll sample 12 sites 20% sample, resulting total 14 sites selected.","code":"g <- ggplot() +    geom_sf(data = ont_hex, fill = \"white\") +   geom_sf(data = final, colour = \"grey70\")  g sel <- run_grts_on_BASS(probs = final,                          num_runs = 1,                          nARUs = 12,                          os = 0.2)  sel_plot <- bind_rows(sel[[\"sites_base\"]],                       sel[[\"sites_over\"]])  g +    geom_sf(data = sel_plot, aes(colour = siteuse), size = 5) +   scale_colour_viridis_d(name = \"Type of\\nsites sampled\", end = 0.7)"},{"path":"https://davidhope.ca/BASSr/articles/BASSr_real.html","id":"stratified-selection","dir":"Articles","previous_headings":"Selection probabilities","what":"Stratified selection","title":"Getting Started - Some real data","text":"First let’s create dummy stratification add hexes plotting  Now ’ll define want sample two strata. Let’s assume don’t really care habitat , don’t want sample one much.  can see ’ve sampled much B , samples , makes sense: 0.2 * 2 = 0.4 rounds 0 wanted sample , define specific sample amounts instead.  Alternatively point (especially strata) might easier supply data frame rather series lists.","code":"final <- mutate(final, strat = c(rep(\"A\", 300), rep(\"B\", 703))) ont_hex_strat <- select(final, \"SampleUnitID\", \"strat\") |>    st_drop_geometry() |>   left_join(ont_hex, y = _, by = \"SampleUnitID\")  g <- ggplot() +    geom_sf(data = ont_hex_strat, aes(fill = strat), alpha = 0.4) +   geom_sf(data = final, colour = \"grey70\") g nARUs <- list(\"A\" = 2, \"B\" = 50)  sel <- run_grts_on_BASS(probs = final,                          num_runs = 1,                          stratum_id = strat,                         nARUs = nARUs,                          os = 0.2)  sel_plot <- bind_rows(sel[[\"sites_base\"]],                       sel[[\"sites_over\"]])  g +    geom_sf(data = sel_plot, aes(colour = siteuse), size = 5) +   scale_colour_viridis_d(name = \"Type of\\nsites sampled\", end = 0.7) nARUs <- list(\"A\" = 2, \"B\" = 50) os <- list(\"A\" = 1, \"B\" = 4)  sel <- run_grts_on_BASS(probs = final,                          num_runs = 1,                          stratum_id = strat,                         nARUs = nARUs,                          os = os,                         seed = 123)  sel_plot <- bind_rows(sel[[\"sites_base\"]],                       sel[[\"sites_over\"]])  g +    geom_sf(data = sel_plot, aes(colour = siteuse), size = 5) +   scale_colour_viridis_d(name = \"Type of\\nsites sampled\", end = 0.7) nARUs <- data.frame(n = c(2, 50),                     strat = c(\"A\", \"B\"),                     n_os = c(1, 4))  sel <- run_grts_on_BASS(probs = final,                          num_runs = 1,                          stratum_id = strat,                         nARUs = nARUs,                          seed = 123)  sel_plot <- bind_rows(sel[[\"sites_base\"]],                       sel[[\"sites_over\"]])  g +    geom_sf(data = sel_plot, aes(colour = siteuse), size = 5) +   scale_colour_viridis_d(name = \"Type of\\nsites sampled\", end = 0.7)"},{"path":"https://davidhope.ca/BASSr/articles/CostBreakDown.html","id":"cost-model-parts","dir":"Articles","previous_headings":"","what":"Cost model parts","title":"Cost Breakdown","text":"cost model comprised three access types: * Truck * ATV * Helicopter basic cost based number ARUs deployed per study area (NN). base rate 30. cost accessing site sum cost surveying site truck, atv helicopter, weighted proportion accessible access type. Truck access assumed preffered first, ATV, helicopter. C=∑piCi=pTCT+pACA+pHCH  C  = \\sum p_iC_i = p_TC_T + p_AC_A + p_HC_H Truck access based primary roads plus buffer 1000m. truck cost based following formula. CT=TdncNNTnc=TdNNT C_{T} = \\frac{T_dn_c N}{N_Tn_c} = \\frac{T_d N}{N_T}  TdT_d daily cost truck usage, set initially 600. NTN_T number ARUs truck crew can deploy (5). can changed later allow differing daily costs based number truck crews, however written now, number crews (ncn_c) increases deployment rate cost equivanetly therefore drops equation. cost ATV deployment equivalent truck costs structure, rate deployment costs different deployment types: CA=AdncNNAnc=AdNNA C_{} = \\frac{A_dn_c N}{N_An_c} = \\frac{A_d N}{N_A} cost helicopter deployment details. can broken four pieces: 1. cost per litre fuel - ClC_l 2. cost setting basecamp - CbC_b 3. cost moving /study area - CfC_{f} 4. cost moving within study area - CsaC_{sa} distances study area, basecamp nearest airport drive cost. distance nearest airport study area Ds−aD_{s-}, study area basecamp Ds−bD_{s-b}, basecamp airport Da−bD_{-b}. distance airport study area less maximum helicopter range Ds−<DmaxD_{s-}<D_{max} basecamp needed. distance basecamp study area greater DmaxD_{max}, fuel cache required. Adding basecamp fuel cache increase cost per litre helicopter fly. Cl={Cl[1],Ds−<DmaxCl[2],else Dsb<DmaxCl[3], otherwise C_l = \\begin{cases}       C_l[1], & \\text{} D_{s-} < D_{max}   \\\\       C_l[2], & \\text{else } D_{s_b} < D_{max}\\\\       C_l[3], & \\text{ otherwise}     \\end{cases} cost flying airport basecamp follows: Cb={0,Ds−<DmaxDa−bCb*+2Da−bShlhCl,otherwise C_b = \\begin{cases} 0,& \\text{} D_{s-} < D_{max}  \\\\ D_{-b} C^*_b + 2\\frac{D_{-b}}{S_h}l_hC_l, & \\text{otherwise} \\end{cases}  Cb*C^*_b cost setting basecamp per kilometre airport($9km−1km^{-1}), ShS_h helicopter relocation speed kilometres per hour (180km/hrkm/hr), lhl_h litres fuel consumed per hour helicopter operational (160l/hrl/hr). next version may want put cap based crew size cost capped weight. flight may require smaller crew. cost flying study area : Cf={2Ds−aCD,Ds−<Dmax2Ds−bCD,otherwise C_{f} = \\begin{cases} 2D_{s-}C_D,& \\text{} D_{s-} < D_{max}  \\\\ 2D_{s-b}C_D, & \\text{otherwise} \\end{cases}  CDC_D cost per kilometre: CD=lhCl+CHSh C_D = \\frac{l_hC_l + C_H}{S_h} cost operating within study area : Csa=NlhCl+CHnhNhHf C_{sa} = N\\frac{l_hC_l + C_H}{n_hN_h}H_f  HfH_f hours flying within study area per day, nhn_h crew size, NhN_h ARUs deployed per day per crew memeber. final cost helicopter : CH=Csa+Cf+Cb C_H = C_{sa} + C_{f} + C_b look practice? Lets look deploying increasing number ARUs looks like study areas just 1 three deployment methods. ’ve set pretend study area intially 250km airport, 100km basecamp, 200km airport basecamp. ’ve compared study area just roads, just atv roads, study area requiring basecamp, study area requiring secondary fuel cache. ’ve also included mixed study area required 30% truck, ATV, helicopter. see cost changes number ARUs deployed. cost deploying given number ARUs Study Area ATV, Truck, Helicopter, mixed method. helicopter includes, base camp (‘Helicopter’; 100km base camp study area, 250 study area airport, 200 km airport base camp), basecamp required (100km base camp study area, 130 study area airport, 200 km airport base camp), base camp secondary fuel cach required (200km base camp study area, 250 km study area airport, 200 km airport base camp). ‘Mixed’ method involves 1/3 truck, ATV, Helicopter access types survey area. calculation shown figure now cost shown cost relative expensive access type ARU deployment size (‘Helicopter - Fuel Cache’ ARU numbers). scaled cost calculated raw cost divided maximum raw cost ARU number.","code":"maxARUs <- 200  d_heli <- tibble(StudyAreaID  = \"Helicopter\",          pr= 0,         sr = 0,         dist_base_sa = 100,         dist_dist_airport_sa = 250,         dsit2airport_base = 200,         AT = \"Highway\"         ) runcost <- function(n,d) {map_df(1:n, estimate_cost_study_area,                                    StudyAreas =d,                                     pr = pr, sr = sr,                                     dist_base_sa = dist_base_sa,                                     dist_airport_sa = dist_dist_airport_sa,                                    dist2airport_base = dsit2airport_base,                                     vars = cost_vars, AirportType = \"Highway\")}  cost_heli <-  runcost(maxARUs, d_heli)  d_heli2 <- mutate(d_heli,                    StudyAreaID  = \"Helicopter - No Base Camp\",         dist_base_sa = 100,         dist_dist_airport_sa = 130,         dsit2airport_base = 200,         AT = \"Highway\"         ) cost_heli2 <-  runcost(maxARUs, d_heli2)   d_heli3 <- tibble(StudyAreaID  = \"Helicopter - Fuel Cache\",          pr= 0,         sr = 0,         dist_base_sa = 200,         dist_dist_airport_sa = 250,         dsit2airport_base = 200,         AT = \"Highway\"         ) cost_heli3 <-  runcost(maxARUs, d_heli3) d_truck <- mutate(d_heli, pr = 1, StudyAreaID  = \"Truck\",         AT = \"Highway\" ) cost_truck <- runcost(maxARUs, d_truck) d_atv <- mutate(d_heli, sr = 1,StudyAreaID  = \"ATV\" ) cost_atv <- runcost(maxARUs, d_atv)  cost_mixed <-    mutate(d_heli, pr = 0.3, sr = 0.3, StudyAreaID = \"Mixed\", AT = \"Highway\") %>%    runcost(maxARUs,.)  cost_test <-  bind_rows(cost_heli, cost_truck, cost_atv, cost_heli2,cost_heli3, cost_mixed) %>%    group_by(narus) %>%    mutate(logcost = log10(RawCost),          scLogCost = logcost / max(logcost)) %>% ungroup ggplot(cost_test, aes(narus,RawCost, colour = StudyAreaID )) + geom_line(size = 1) +   scale_colour_viridis_d(direction = -1) +   labs(colour = \"Access type\", x = \"Number of ARUs deployed\", y = \"Raw Cost Value\") # scale_y_continuous(trans = 'log1p') ggplot(cost_test, aes(narus,scLogCost, colour = StudyAreaID )) +    geom_line(size = 1) +   scale_colour_viridis_d(direction = -1) +   labs(colour = \"Access type\", x = \"Number of ARUs deployed\", y = \"Scaled Log Cost\")"},{"path":"https://davidhope.ca/BASSr/articles/CostBreakDown.html","id":"baseline-variables","dir":"Articles","previous_headings":"","what":"Baseline variables","title":"Cost Breakdown","text":"current version, can adjust cost fuel based airport type","code":"BASSr::cost_vars %>% as_tibble() %>%    dplyr::select(-helicopter_airport_cost_per_l) %>%    pivot_longer(names_to = \"Variable\", values_to = \"Value\", cols = everything()) %>%    # BASSr::cost_vars$helicopter_airport_cost_per_l   knitr::kable() BASSr::cost_vars$helicopter_airport_cost_per_l %>%    knitr::kable()"},{"path":"https://davidhope.ca/BASSr/articles/Workflow.html","id":"packages-and-settings","dir":"Articles","previous_headings":"","what":"Packages and settings","title":"BASSr Workflow","text":"","code":"library(dplyr) ##  ## Attaching package: 'dplyr' ## The following objects are masked from 'package:stats': ##  ##     filter, lag ## The following objects are masked from 'package:base': ##  ##     intersect, setdiff, setequal, union library(ggplot2) library(tidyr) library(BASSr) library(sf) ## Linking to GEOS 3.12.1, GDAL 3.8.4, PROJ 9.4.0; sf_use_s2() is TRUE"},{"path":"https://davidhope.ca/BASSr/articles/Workflow.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"BASSr Workflow","text":"goal vignette provide guide work implementing BASS survey design. currently quite peculiarities script workflow elucidate bit .","code":""},{"path":"https://davidhope.ca/BASSr/articles/Workflow.html","id":"step-1--define-your-area-of-interest","dir":"Articles","previous_headings":"","what":"Step 1. Define your area of interest","title":"BASSr Workflow","text":"now ’ll work package sf’s nc layer. need sf package installed (install.packages('sf')). need projection usess metres instead lat/lon may transform spatial objects. just survey western half state simplicity (shown grey).  today, lets aim survey North Carolina using 1km sample units 34km study areas.","code":"nc <- st_read(system.file(\"shape/nc.shp\", package=\"sf\")) %>%    st_transform(crs = '+proj=utm +zone=17 +ellps=GRS80 +units=m +no_defs ',check=T, partial=F) ## Reading layer `nc' from data source  ##   `/home/runner/work/_temp/Library/sf/shape/nc.shp' using driver `ESRI Shapefile' ## Simple feature collection with 100 features and 14 fields ## Geometry type: MULTIPOLYGON ## Dimension:     XY ## Bounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965 ## Geodetic CRS:  NAD27 nc_coords <- st_centroid(nc) %>%    st_coordinates %>%    as_tibble ## Warning: st_centroid assumes attributes are constant over geometries nc_for_survey <- bind_cols(nc, nc_coords) %>%    filter(X < 600000) ggplot(nc) + geom_sf() + geom_sf(data = nc_for_survey, fill = 'grey')"},{"path":"https://davidhope.ca/BASSr/articles/Workflow.html","id":"step-2--create-hexagons","dir":"Articles","previous_headings":"","what":"Step 2. Create hexagons","title":"BASSr Workflow","text":"Often usefully done outside R, habitat costs incorporated hexagons, ’ll run detail data formatted.  example study area. study area within North Carolina (pink) deploy .","code":"SA <- create_hexes(land = nc_for_survey,                        hex_size =  100000,                        units = 'ha' ) ggplot(SA) +    geom_sf(data = nc) +    geom_sf(fill = 'grey', alpha = 0.5) su_ex <- create_hexes(land = SA[16,],                        hex_size =  100,                        units = 'ha' )  ggplot() +     geom_sf(data = nc, fill = 'lightpink') +   geom_sf(data = SA[16,], fill = NA) +   geom_sf(data = su_ex, fill = NA) +   coord_sf(xlim =st_bbox(SA[16,])[c(1,3)], ylim = st_bbox(SA[16,])[c(2,4)]) st_area(SA[16,]) ## 1e+09 [m^2] pHA_region <- tibble(lc = 1:18) %>%    mutate(pHA_region = runif(18),          pHA_region = pHA_region/sum(pHA_region),          varbeta = pHA_region*0.2) # varbeta <- 0.2 estBetaParams <- function(mu, var) {   alpha <- ((1 - mu) / var - 1 / mu) * mu ^ 2   beta <- alpha * (1 / mu - 1)   return(params = list(alpha = alpha, beta = beta)) }  beta_values <- estBetaParams(pHA_region$pHA_region, pHA_region$varbeta) SA_LC <-  expand_grid(hex_id = unique(SA$hex_id), lc = 1:18) %>%    left_join(pHA_region, by = 'lc') %>%    mutate(LandCover = glue::glue(\"LC{stringr::str_pad(lc,width = 2, side = 'left', pad = 0 )}\"),          pha = rbeta(nrow(.),beta_values$alpha,beta_values$beta)) %>%           # a = (pHA_region**2)*((1-pHA_region)/(varbeta)- (1/pHA_region)),          # pha = rbeta(nrow(.),a,a*(1/pHA_region-1))) %>%    group_by(hex_id) %>%    mutate(ha = pha/sum(pha)*1e9*.0001,          pha = ha/sum(ha)) %>% ungroup"},{"path":"https://davidhope.ca/BASSr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"David Hope. Maintainer.","code":""},{"path":"https://davidhope.ca/BASSr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Hope D (2025). BASSr: Benefit Applied Strategic Sampling. R package version 0.3.0, https://github.com/dhope/BASSr.","code":"@Manual{,   title = {BASSr: Benefit Applied Strategic Sampling},   author = {David Hope},   year = {2025},   note = {R package version 0.3.0},   url = {https://github.com/dhope/BASSr}, }"},{"path":[]},{"path":"https://davidhope.ca/BASSr/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Benefit Applied Strategic Sampling","text":"code associated CWS Ontario’s preferred approach sampling Boreal Birds boreal forest. code allow start understanding process. vignettes associated package good place start.","code":""},{"path":"https://davidhope.ca/BASSr/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Benefit Applied Strategic Sampling","text":"Install development version GitHub:","code":"devtools::install_github(\"dhope/BASSr\")"},{"path":"https://davidhope.ca/BASSr/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Benefit Applied Strategic Sampling","text":"See vignettes now. Details come.","code":"devtools::install_github(\"dhope/BASSr\", build_vignettes = TRUE)"},{"path":"https://davidhope.ca/BASSr/reference/BASSr-defunct.html","id":null,"dir":"Reference","previous_headings":"","what":"BASSr defunct functions — BASSr-defunct","title":"BASSr defunct functions — BASSr-defunct","text":"BASSr defunct functions","code":""},{"path":"https://davidhope.ca/BASSr/reference/BASSr-defunct.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BASSr defunct functions — BASSr-defunct","text":"","code":"clean_forBass(...)  run_full_BASS_w_selection()"},{"path":"https://davidhope.ca/BASSr/reference/BASSr-defunct.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"BASSr defunct functions — BASSr-defunct","text":"... Original function arguments","code":""},{"path":"https://davidhope.ca/BASSr/reference/BASSr-deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"BASSr deprecated functions — BASSr-deprecated","title":"BASSr deprecated functions — BASSr-deprecated","text":"Deprecated functions longer useful.","code":""},{"path":"https://davidhope.ca/BASSr/reference/BASSr-deprecated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BASSr deprecated functions — BASSr-deprecated","text":"","code":"subsample_grts_and_calc_benefit()  extract_habitat_cost()  genraster()  noGRTS_BASS_run()  getresults_BASS()"},{"path":[]},{"path":"https://davidhope.ca/BASSr/reference/BASSr.html","id":null,"dir":"Reference","previous_headings":"","what":"BASSr: Benefit Applied Strategic Sampling in R — BASSr","title":"BASSr: Benefit Applied Strategic Sampling in R — BASSr","text":"BASSr package implements Benefit Applied Strategic Sampling","code":""},{"path":[]},{"path":"https://davidhope.ca/BASSr/reference/StudyArea_hexes.html","id":null,"dir":"Reference","previous_headings":"","what":"BASSr data needed for example study area — StudyArea_hexes","title":"BASSr data needed for example study area — StudyArea_hexes","text":"list containing cost, landcover, id example study area","code":""},{"path":"https://davidhope.ca/BASSr/reference/StudyArea_hexes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BASSr data needed for example study area — StudyArea_hexes","text":"","code":"StudyArea_hexes"},{"path":"https://davidhope.ca/BASSr/reference/StudyArea_hexes.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"BASSr data needed for example study area — StudyArea_hexes","text":"list 2 dataframes one character string: cost cost estimates sample unit landcover SF polygon land cover percentages sample unit study_area Unique identifier Study Area","code":""},{"path":"https://davidhope.ca/BASSr/reference/StudyArea_hexes.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"BASSr data needed for example study area — StudyArea_hexes","text":"BASSr analysis N. Ontario","code":""},{"path":"https://davidhope.ca/BASSr/reference/all_study_areas.html","id":null,"dir":"Reference","previous_headings":"","what":"All of Ontario's Study Areas — all_study_areas","title":"All of Ontario's Study Areas — all_study_areas","text":"simple features (package SF) object Ontario's Study Areas associated Land Cover","code":""},{"path":"https://davidhope.ca/BASSr/reference/all_study_areas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"All of Ontario's Study Areas — all_study_areas","text":"","code":"all_study_areas"},{"path":"https://davidhope.ca/BASSr/reference/all_study_areas.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"All of Ontario's Study Areas — all_study_areas","text":"data frame 746 rows 19 variables: StudyAreaID Unique Identifier study area TOT_HA Total hectares study area D_CLC15 Dominant land cover study area LC.. Hectares covered landcover type (00-18) geometry SF geometry","code":""},{"path":"https://davidhope.ca/BASSr/reference/all_study_areas.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"All of Ontario's Study Areas — all_study_areas","text":"Hexagons generated R, landcover extracted National Land Cover 2015 (https://open.canada.ca/data/en/dataset/4e615eae-b90c-420b-adee-2ca35896caf6).","code":""},{"path":"https://davidhope.ca/BASSr/reference/allhexes.html","id":null,"dir":"Reference","previous_headings":"","what":"Run speed bass on all hexagons and all samples — allhexes","title":"Run speed bass on all hexagons and all samples — allhexes","text":"Run speed bass hexagons samples","code":""},{"path":"https://davidhope.ca/BASSr/reference/allhexes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run speed bass on all hexagons and all samples — allhexes","text":"","code":"allhexes(hexes, samples, total, w, printDets = FALSE)"},{"path":"https://davidhope.ca/BASSr/reference/allhexes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run speed bass on all hexagons and all samples — allhexes","text":"hexes Matrix hexagon land covers. Rows hexagons, columns land cover types samples Matrix hexagon land covers random sample. Rows hexagons, columns land cover types total Vector total land cover. values individual land cover types w vector weights land cover value printDets print details function calculation. debugging.","code":""},{"path":"https://davidhope.ca/BASSr/reference/calculate_PPS_hab_inlc_pr.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Propbability Proportional to Size (PPS) inclusion probabilities — calculate_PPS_hab_inlc_pr","title":"Calculate Propbability Proportional to Size (PPS) inclusion probabilities — calculate_PPS_hab_inlc_pr","text":"See information: https://www150.statcan.gc.ca/n1/en/pub/12-001-x/2011001/article/11450-eng.pdf?st=0oyBln55 https://en.wikipedia.org/wiki/Probability-proportional--size_sampling","code":""},{"path":"https://davidhope.ca/BASSr/reference/calculate_PPS_hab_inlc_pr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Propbability Proportional to Size (PPS) inclusion probabilities — calculate_PPS_hab_inlc_pr","text":"","code":"calculate_PPS_hab_inlc_pr(   land_hex,   hex_id = hex_id,   stratum_id = NULL,   quiet = FALSE )"},{"path":"https://davidhope.ca/BASSr/reference/calculate_PPS_hab_inlc_pr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Propbability Proportional to Size (PPS) inclusion probabilities — calculate_PPS_hab_inlc_pr","text":"land_hex (Spatial) Data frame. Land Cover data hexagon. non-spatial, converted spatial sf data frame using crs coords arguments. Requires columns identifying Hex ID well Stratum ID (see hex_id stratum_id respectively). hex_id Column. Identifies hexagon IDs (e.g., default hex_id). stratum_id Column. Identifies larger area (e.g., StudyAreaID Province). quiet Logical. Whether suppress progress messages.","code":""},{"path":"https://davidhope.ca/BASSr/reference/calculate_PPS_hab_inlc_pr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Propbability Proportional to Size (PPS) inclusion probabilities — calculate_PPS_hab_inlc_pr","text":"tibble selection weights PPS","code":""},{"path":"https://davidhope.ca/BASSr/reference/calculate_PPS_hab_inlc_pr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Propbability Proportional to Size (PPS) inclusion probabilities — calculate_PPS_hab_inlc_pr","text":"","code":"calculate_PPS_hab_inlc_pr(land_hex = psu_hexagons) #> ℹ Spatial object land_hex should be POINTs not POLYGONs #> • Don't worry, I'll fix it! #> • Assuming constant attributes and using centroids as points #> Simple feature collection with 33 features and 10 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 25 ymin: 43.30127 xmax: 275 ymax: 259.8076 #> Projected CRS: NAD83 / Ontario MNR Lambert #> First 10 features: #>    hex_id province water             LC1            LC2            LC3 #> 1   SA_09       ON FALSE  15155.44 [m^2] 549926.1 [m^2] 634363.6 [m^2] #> 2   SA_10       ON FALSE  73612.16 [m^2] 400536.7 [m^2] 452498.3 [m^2] #> 3   SA_11       ON FALSE 171040.02 [m^2] 309604.1 [m^2] 277128.1 [m^2] #> 4   SA_14       ON FALSE  19485.57 [m^2] 565081.6 [m^2] 710140.8 [m^2] #> 5   SA_15       ON  TRUE 177535.21 [m^2] 335584.8 [m^2] 686325.1 [m^2] #> 6   SA_16       ON FALSE 173205.08 [m^2] 339915.0 [m^2] 911491.7 [m^2] #> 7   SA_17       ON  TRUE 121243.56 [m^2] 443838.0 [m^2] 770762.6 [m^2] #> 8   SA_18       ON  TRUE 132068.87 [m^2] 467653.7 [m^2] 671169.7 [m^2] #> 9   SA_19       ON  TRUE 173205.08 [m^2] 290118.5 [m^2] 387546.4 [m^2] #> 10  SA_22       ON FALSE 359400.54 [m^2] 171040.0 [m^2] 476314.0 [m^2] #>                LC4             LC5           LC6 p_sel_PPS_hab #> 1   751277.0 [m^2]  941802.6 [m^2] 2030830 [m^2]     0.1710617 #> 2  1162639.1 [m^2]  952627.9 [m^2] 1877110 [m^2]     0.1688158 #> 3  1091192.0 [m^2]  792413.2 [m^2] 2284142 [m^2]     0.1662089 #> 4   902831.5 [m^2]  772927.7 [m^2] 2017839 [m^2]     0.1766716 #> 5   911491.7 [m^2]  664674.5 [m^2] 2212695 [m^2]     0.1813016 #> 6   632198.5 [m^2]  835714.5 [m^2] 2095781 [m^2]     0.1880288 #> 7   731791.5 [m^2]  762102.4 [m^2] 2158568 [m^2]     0.1826062 #> 8   926647.2 [m^2] 1054385.9 [m^2] 1732051 [m^2]     0.1900891 #> 9  1145318.6 [m^2]  872520.6 [m^2] 2119597 [m^2]     0.1727177 #> 10  904996.5 [m^2] 1115007.7 [m^2] 1961548 [m^2]     0.1958207 #>                geometry #> 1   POINT (25 43.30127) #> 2   POINT (25 129.9038) #> 3   POINT (25 216.5064) #> 4   POINT (50 86.60254) #> 5   POINT (50 173.2051) #> 6   POINT (50 259.8076) #> 7   POINT (75 43.30127) #> 8   POINT (75 129.9038) #> 9   POINT (75 216.5064) #> 10 POINT (100 86.60254)"},{"path":"https://davidhope.ca/BASSr/reference/calculate_benefit.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the benefit of a hexagon from grts results. — calculate_benefit","title":"Calculate the benefit of a hexagon from grts results. — calculate_benefit","text":"Calculate benefit hexagon  grts results.","code":""},{"path":"https://davidhope.ca/BASSr/reference/calculate_benefit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the benefit of a hexagon from grts results. — calculate_benefit","text":"","code":"calculate_benefit(   land_hex,   samples,   hex_id = hex_id,   stratum_id = NULL,   non_random_set = NULL,   land_cover_weights = NULL,   crs = 4326,   coords = c(\"lon\", \"lat\"),   quiet = FALSE )"},{"path":"https://davidhope.ca/BASSr/reference/calculate_benefit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the benefit of a hexagon from grts results. — calculate_benefit","text":"land_hex (Spatial) Data frame. Land Cover data hexagon. non-spatial, converted spatial sf data frame using crs coords arguments. Requires columns identifying Hex ID well Stratum ID (see hex_id stratum_id respectively). samples (Spatial) Data frame. Results draw_random_samples(). hex_id Column. Identifies hexagon IDs (e.g., default hex_id). stratum_id Column. Identifies larger area (e.g., StudyAreaID Province). non_random_set Character vector. hex_ids hexagons include non randomly selected set. land_cover_weights Data frame. Proportional weights (weights column) specific types landcover (lc column). lc correspond landcover column names hex data. crs Numeric, character, sf/sfc. Coordinate reference system. Must valid input sf::st_crs(). coords Character vector. Names columns containing X Y coordinates (default c(\"lon\", \"lat\")). quiet Logical. Whether suppress progress messages.","code":""},{"path":"https://davidhope.ca/BASSr/reference/calculate_benefit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the benefit of a hexagon from grts results. — calculate_benefit","text":"Spatial data frame benefits per hex","code":""},{"path":"https://davidhope.ca/BASSr/reference/calculate_benefit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the benefit of a hexagon from grts results. — calculate_benefit","text":"","code":"# Using example data psu_hexagons and psu_samples  calculate_benefit(   land_hex = psu_hexagons,   samples = psu_samples,   non_random_set = c(\"SA_09\", \"SA_22\", \"SA_47\")) #> ℹ Spatial object land_hex should be POINTs not POLYGONs #> • Don't worry, I'll fix it! #> • Assuming constant attributes and using centroids as points #> Simple feature collection with 33 features and 2 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 25 ymin: 43.30127 xmax: 275 ymax: 259.8076 #> Projected CRS: NAD83 / Ontario MNR Lambert #> First 10 features: #>    hex_id     benefit             geometry #> 1   SA_09 0.011928502  POINT (25 43.30127) #> 2   SA_10 0.019759576  POINT (25 129.9038) #> 3   SA_11 0.018844331  POINT (25 216.5064) #> 4   SA_14 0.014763746  POINT (50 86.60254) #> 5   SA_15 0.010130728  POINT (50 173.2051) #> 6   SA_16 0.009821685  POINT (50 259.8076) #> 7   SA_17 0.011240254  POINT (75 43.30127) #> 8   SA_18 0.016422632  POINT (75 129.9038) #> 9   SA_19 0.016226578  POINT (75 216.5064) #> 10  SA_22 0.012322357 POINT (100 86.60254)  # Specify a non-random set  calculate_benefit(  land_hex = psu_hexagons,  samples = psu_samples,  non_random_set = c(\"SA_09\", \"SA_22\", \"SA_47\")) #> ℹ Spatial object land_hex should be POINTs not POLYGONs #> • Don't worry, I'll fix it! #> • Assuming constant attributes and using centroids as points #> Simple feature collection with 33 features and 2 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 25 ymin: 43.30127 xmax: 275 ymax: 259.8076 #> Projected CRS: NAD83 / Ontario MNR Lambert #> First 10 features: #>    hex_id     benefit             geometry #> 1   SA_09 0.011928502  POINT (25 43.30127) #> 2   SA_10 0.019759576  POINT (25 129.9038) #> 3   SA_11 0.018844331  POINT (25 216.5064) #> 4   SA_14 0.014763746  POINT (50 86.60254) #> 5   SA_15 0.010130728  POINT (50 173.2051) #> 6   SA_16 0.009821685  POINT (50 259.8076) #> 7   SA_17 0.011240254  POINT (75 43.30127) #> 8   SA_18 0.016422632  POINT (75 129.9038) #> 9   SA_19 0.016226578  POINT (75 216.5064) #> 10  SA_22 0.012322357 POINT (100 86.60254)  # Without GRTS  non_grts_samples <- draw_random_samples(   land_hex = psu_hexagons,   num_runs = 3,   n_samples = 10,   use_grts = FALSE) #> ℹ Spatial object land_hex should be POINTs not POLYGONs #> • Don't worry, I'll fix it! #> • Assuming constant attributes and using centroids as points  calculate_benefit(  land_hex = psu_hexagons,  samples = non_grts_samples) #> ℹ Spatial object land_hex should be POINTs not POLYGONs #> • Don't worry, I'll fix it! #> • Assuming constant attributes and using centroids as points #> Simple feature collection with 33 features and 2 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 25 ymin: 43.30127 xmax: 275 ymax: 259.8076 #> Projected CRS: NAD83 / Ontario MNR Lambert #> First 10 features: #>    hex_id     benefit             geometry #> 1   SA_09 0.008367774  POINT (25 43.30127) #> 2   SA_10 0.010510586  POINT (25 129.9038) #> 3   SA_11 0.007752895  POINT (25 216.5064) #> 4   SA_14 0.006910977  POINT (50 86.60254) #> 5   SA_15 0.001677754  POINT (50 173.2051) #> 6   SA_16 0.004713814  POINT (50 259.8076) #> 7   SA_17 0.005191574  POINT (75 43.30127) #> 8   SA_18 0.012027388  POINT (75 129.9038) #> 9   SA_19 0.006278050  POINT (75 216.5064) #> 10  SA_22 0.010723963 POINT (100 86.60254)"},{"path":"https://davidhope.ca/BASSr/reference/calculate_inclusion_probs.html","id":null,"dir":"Reference","previous_headings":"","what":"BASS cost benefit calculation — calculate_inclusion_probs","title":"BASS cost benefit calculation — calculate_inclusion_probs","text":"Calculate cost-benefits inclusion probabilities.","code":""},{"path":"https://davidhope.ca/BASSr/reference/calculate_inclusion_probs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BASS cost benefit calculation — calculate_inclusion_probs","text":"","code":"calculate_inclusion_probs(   benefits,   costs,   hex_id = hex_id,   stratum_id = NULL,   omit_flag = NULL,   benefit_weight = 0.5 )"},{"path":"https://davidhope.ca/BASSr/reference/calculate_inclusion_probs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"BASS cost benefit calculation — calculate_inclusion_probs","text":"benefits Spatial Data frame. Benefits associated hexagon (output calculate_benefits()). costs Data frame. Costs hexagon RawCost format. hex_id Column. Identifies hexagon IDs (e.g., default hex_id). stratum_id Column. Identifies larger area (e.g., StudyAreaID Province). omit_flag Column identifying hexes omit (e.g., water hexes). benefit_weight Numeric. Weight assigned benefit selection probabilities. 0.5 equal weighting cost benefits. 1.0 zero weighting cost. Default 0.5.","code":""},{"path":"https://davidhope.ca/BASSr/reference/calculate_inclusion_probs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"BASS cost benefit calculation — calculate_inclusion_probs","text":"data frame full inclusion probabilities hex.","code":""},{"path":"https://davidhope.ca/BASSr/reference/calculate_inclusion_probs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"BASS cost benefit calculation — calculate_inclusion_probs","text":"","code":"b <- calculate_benefit(land_hex = psu_hexagons,                        samples = psu_samples) #> ℹ Spatial object land_hex should be POINTs not POLYGONs #> • Don't worry, I'll fix it! #> • Assuming constant attributes and using centroids as points  inc <- calculate_inclusion_probs(   benefits = b,   costs = psu_costs)  # Omit water hexes (identified by column `water`)  inc <- calculate_inclusion_probs(   benefits = b,   costs = psu_costs,   omit_flag = water)"},{"path":"https://davidhope.ca/BASSr/reference/calculate_z_scores.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate z-scores for each hexagon by sum of individual z scores — calculate_z_scores","title":"Calculate z-scores for each hexagon by sum of individual z scores — calculate_z_scores","text":"Calculate z-scores hexagon sum individual z scores","code":""},{"path":"https://davidhope.ca/BASSr/reference/calculate_z_scores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate z-scores for each hexagon by sum of individual z scores — calculate_z_scores","text":"","code":"calculate_z_scores(land_hex, hex_id, stratum_id = NULL, quiet = FALSE)"},{"path":"https://davidhope.ca/BASSr/reference/calculate_z_scores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate z-scores for each hexagon by sum of individual z scores — calculate_z_scores","text":"land_hex (Spatial) Data frame. Land Cover data hexagon. non-spatial, converted spatial sf data frame using crs coords arguments. Requires columns identifying Hex ID well Stratum ID (see hex_id stratum_id respectively). hex_id Column. Identifies hexagon IDs (e.g., default hex_id). stratum_id Column. Identifies larger area (e.g., StudyAreaID Province). quiet Logical. Whether suppress progress messages.","code":""},{"path":"https://davidhope.ca/BASSr/reference/calculate_z_scores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate z-scores for each hexagon by sum of individual z scores — calculate_z_scores","text":"data frame","code":""},{"path":"https://davidhope.ca/BASSr/reference/calculate_z_scores.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate z-scores for each hexagon by sum of individual z scores — calculate_z_scores","text":"","code":"calculate_z_scores(psu_hexagons, hex_id) #> ℹ Spatial object land_hex should be POINTs not POLYGONs #> • Don't worry, I'll fix it! #> • Assuming constant attributes and using centroids as points #> # A tibble: 33 × 3 #>    hex_id avg_abs_diff avg_z_score #>    <glue>        <dbl>       <dbl> #>  1 SA_09       115886.    -0.0907  #>  2 SA_10       103092.    -0.187   #>  3 SA_11       151740.    -0.138   #>  4 SA_14       131041.    -0.00750 #>  5 SA_15       113327.     0.0536  #>  6 SA_16       149411.     0.117   #>  7 SA_17       157743.     0.0766  #>  8 SA_18       113021.     0.0437  #>  9 SA_19       104470.    -0.0762  #> 10 SA_22       109150.     0.110   #> # ℹ 23 more rows"},{"path":"https://davidhope.ca/BASSr/reference/clean_land_cover.html","id":null,"dir":"Reference","previous_headings":"","what":"Clean land cover habitat data — clean_land_cover","title":"Clean land cover habitat data — clean_land_cover","text":"general function clean land cover columns.","code":""},{"path":"https://davidhope.ca/BASSr/reference/clean_land_cover.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clean land cover habitat data — clean_land_cover","text":"","code":"clean_land_cover(land_raw, pattern = \"CLC15_\", append = \"\", quiet = FALSE)"},{"path":"https://davidhope.ca/BASSr/reference/clean_land_cover.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clean land cover habitat data — clean_land_cover","text":"land_raw (Spatial) data frame. Land Cover data cleaned. pattern Character. Pattern match replace 'LC' append Character. Text append end land cover code quiet Logical. Whether suppress progress messages.","code":""},{"path":"https://davidhope.ca/BASSr/reference/clean_land_cover.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clean land cover habitat data — clean_land_cover","text":"(Spatial) Data frame cleaned land cover column names.","code":""},{"path":"https://davidhope.ca/BASSr/reference/clean_land_cover.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clean land cover habitat data — clean_land_cover","text":"","code":"psu_hex_clean <- clean_land_cover(psu_hex_dirty, pattern = \"CLC0013_\") #> ℹ Renaming land cover columns #> • From: CLC0013_1, CLC0013_2, CLC0013_3, CLC0013_4, CLC0013_5, CLC0013_6 #> • To: LC01, LC02, LC03, LC04, LC05, LC06"},{"path":"https://davidhope.ca/BASSr/reference/clrfile.html","id":null,"dir":"Reference","previous_headings":"","what":"rgb colour codes to plot 2015 National Land Cover. — clrfile","title":"rgb colour codes to plot 2015 National Land Cover. — clrfile","text":"dataset containing red, blue, green values associated land cover types found 2015 Canadian National Land Cover Classification","code":""},{"path":"https://davidhope.ca/BASSr/reference/clrfile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"rgb colour codes to plot 2015 National Land Cover. — clrfile","text":"","code":"clrfile"},{"path":"https://davidhope.ca/BASSr/reference/clrfile.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"rgb colour codes to plot 2015 National Land Cover. — clrfile","text":"data frame 20 rows 6 variables: Value price, US dollars red weight diamond, carats green weight diamond, carats blue weight diamond, carats rgb weight diamond, carats LCC_NAME weight diamond, carats","code":""},{"path":"https://davidhope.ca/BASSr/reference/clrfile.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"rgb colour codes to plot 2015 National Land Cover. — clrfile","text":"https://open.canada.ca/data/en/dataset/4e615eae-b90c-420b-adee-2ca35896caf6","code":""},{"path":"https://davidhope.ca/BASSr/reference/common_docs.html","id":null,"dir":"Reference","previous_headings":"","what":"Common arguments and documentation for various functions — common_docs","title":"Common arguments and documentation for various functions — common_docs","text":"Common arguments documentation various functions","code":""},{"path":"https://davidhope.ca/BASSr/reference/common_docs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Common arguments and documentation for various functions — common_docs","text":"num_runs Numeric. Number times draw random samples. n_samples Numeric. Number samples draw run. land_hex (Spatial) Data frame. Land Cover data hexagon. non-spatial, converted spatial sf data frame using crs coords arguments. Requires columns identifying Hex ID well Stratum ID (see hex_id stratum_id respectively). stratum_id Column. Identifies larger area (e.g., StudyAreaID Province). hex_id Column. Identifies hexagon IDs (e.g., default hex_id). omit_flag Column identifying hexes omit (e.g., water hexes). costs Data frame. Costs hexagon RawCost format. crs Numeric, character, sf/sfc. Coordinate reference system. Must valid input sf::st_crs(). coords Character vector. Names columns containing X Y coordinates (default c(\"lon\", \"lat\")). non_random_set Character vector. hex_ids hexagons include non randomly selected set. benefit_weight Numeric. Weight assigned benefit selection probabilities. 0.5 equal weighting cost benefits. 1.0 zero weighting cost. Default 0.5. land_cover_weights Data frame. Proportional weights (weights column) specific types landcover (lc column). lc correspond landcover column names hex data. return_grts Logical. Return spsurvey object(s). ... Extra named arguments passed spsurvey::grts(). seed Numeric. Random seed use random sampling. Seed applies specific sampling events (change seed environment). NULL set seed. quiet Logical. Whether suppress progress messages.","code":""},{"path":"https://davidhope.ca/BASSr/reference/common_docs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Common arguments and documentation for various functions — common_docs","text":"Use @inheritParams common_docs include function documentation matching argument (include matching args)","code":""},{"path":"https://davidhope.ca/BASSr/reference/common_docs.html","id":"extra-arguments","dir":"Reference","previous_headings":"","what":"Extra arguments","title":"Common arguments and documentation for various functions — common_docs","text":"Extra named arguments spsurvey::grts() can also passed via .... particular, note default values mindis (minimum distance sites) NULL, maxtry (maximum attempts try obtain minimum distance sites) 10.","code":""},{"path":"https://davidhope.ca/BASSr/reference/cost_vars.html","id":null,"dir":"Reference","previous_headings":"","what":"Variables for cost estimation — cost_vars","title":"Variables for cost estimation — cost_vars","text":"Cost variables estimate_cost_study_area","code":""},{"path":"https://davidhope.ca/BASSr/reference/cost_vars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variables for cost estimation — cost_vars","text":"","code":"cost_vars"},{"path":"https://davidhope.ca/BASSr/reference/cost_vars.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Variables for cost estimation — cost_vars","text":"list 18 variables used calculate cost model N Ontario: truck_cost_per_day Cost truck use per day per crew, dollars truck_n_crews Number crews truck surveys truck_arus_per_crew_per_day number arus deployed per crew per day atv_cost_per_day Cost ATV use per day per crew, dollars atv_n_crews Number crews ATV surveys atv_arus_per_crew_per_day Number arus deployed per crew per day helicopter_cost_per_hour Cost helicopter rental per hour, dollars helicopter_max_km_from_base Maximum range helicopter fuelling base, kilometres helicopter_base_setup_cost_per_km Cost setting base helicopter use distance airport, km helicopter_l_per_hour Helicopter fuel usage per hour, litres helicopter_crew_size Helicopter crew size helicopter_aru_per_person_per_day Number arus deployed per day per person helicopter_relocation_speed Speed movement helicopter relocating, km per hour helicopter_airport_cost_per_l Cost heli fuel airport, dollars per litre helicopter_base_cost_per_l Cost heli fuel basecamp, dollars per litre helicopter_2nd_base_cost_per_l Cost heli fuel remote fuel cache, dollars per litre helicopter_hours_flying_within_sa_per_day Number hours helicopter spends flying study area per day.","code":""},{"path":"https://davidhope.ca/BASSr/reference/cost_vars.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Variables for cost estimation — cost_vars","text":"Advice Rich Russell","code":""},{"path":"https://davidhope.ca/BASSr/reference/create_hexes.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Hexagonal grid — create_hexes","title":"Create Hexagonal grid — create_hexes","text":"Function takes landscape sf object returns hexagonal grid given size. Allowed inputs hectres ('ha'), metres squared ('m2'), metres kilometres ('m', 'km') diameter hexagon","code":""},{"path":"https://davidhope.ca/BASSr/reference/create_hexes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Hexagonal grid — create_hexes","text":"","code":"create_hexes(   land,   hex_size,   units = NULL,   hex_prefix = \"SA_\",   linear_type = \"short_diagonal\" )"},{"path":"https://davidhope.ca/BASSr/reference/create_hexes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Hexagonal grid — create_hexes","text":"land sf Spatial. Area create hexagonal grid. Must valid CRS. lat/lon (.e. CRS 4326) projected 3347 ensure proper units. hex_size Numeric Units. Size hexagon area diagonal diameter. Can bear number (see units) units object units embedded. See details specifics. units Character. Units hex_size \"m\", \"m2\", \"km\", \"km2\", \"ha\". Ignored hex_size units object. hex_prefix Character. Text prefix hexagon IDs. Default \"SA_\" results hexagon ids \"SA_01\", etc. linear_type Character. Type diameter use specifying linear hexagonal grid sizes. One \"short_diagonal\" (default; short diameter side side, centroid centroid), \"long_diagonal\" (long diameter vertex vertex passing centre hex).","code":""},{"path":"https://davidhope.ca/BASSr/reference/create_hexes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Hexagonal grid — create_hexes","text":"Returns sf polygon layer hexagons unique IDs","code":""},{"path":"https://davidhope.ca/BASSr/reference/create_hexes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create Hexagonal grid — create_hexes","text":"hex_size provided units object (.e., units::set_units(100, km^2)) units can area length unit recognized units package convertible m m2. Otherwise, using bare number hex_size providing units character units, must one \"m\", \"m2\", \"km\", \"km2\", \"ha\". example, hex_size = units::set_units(100, ft) work, hex_size = 100, units = \"ft\" .","code":""},{"path":"https://davidhope.ca/BASSr/reference/create_hexes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Hexagonal grid — create_hexes","text":"","code":"library(sf) #> Linking to GEOS 3.12.1, GDAL 3.8.4, PROJ 9.4.0; sf_use_s2() is TRUE library(ggplot2) plot <- st_polygon(list(cbind(c(-90,-90,-85,-85,-90),                               c(50,55,55,50,50)))) |>   st_sfc(crs = 4326) |>   st_transform(3347)  ggplot() +   geom_sf(data = plot, fill = \"white\")   # Create grid by area - 1000km2 grid <- create_hexes(plot, hex_size = 1000, units = \"km2\")  # Check the area st_area(grid[1,]) |>   units::set_units(\"km2\") #> 1000 [km^2]  # Check the visual ggplot() +   geom_sf(data = plot, fill = \"white\") +   geom_sf(data = grid, fill = NA)   # Create grid by diameter - 33.98088 km from side to side grid2 <- create_hexes(plot, hex_size = 33.98088, units = \"km\")  # Check the area - Hah! A hexagon with the diameter of 33.98088 km has an area of ~1,000km st_area(grid2[1,]) |>   units::set_units(\"km2\") #> 999.9997 [km^2]  # Check the visual - Identical ggplot() +   geom_sf(data = plot, fill = \"white\") +   geom_sf(data = grid2, fill = NA)   # Diameter of a 1000 km2 hexagon is area_km2 <- 1000 (sqrt(2 * area_km2 / (3 * sqrt(3)))) * sqrt(3) #> [1] 33.98088  # Create grid by hectare grid <- create_hexes(plot, hex_size = 40000, units = \"ha\") ggplot() +   geom_sf(data = plot, fill = \"white\") +   geom_sf(data = grid, fill = NA)   # Create grid with pre-set units area <- units::set_units(1000, \"km2\", mode = \"character\") grid <- create_hexes(plot, hex_size = area) ggplot() +   geom_sf(data = plot, fill = \"white\") +   geom_sf(data = grid, fill = NA)"},{"path":"https://davidhope.ca/BASSr/reference/create_sites.html","id":null,"dir":"Reference","previous_headings":"","what":"Create sampling sites within hexagons — create_sites","title":"Create sampling sites within hexagons — create_sites","text":"Creates grid sites within hexagon grid cells created create_hexes(). sites can sampled sample_sites().","code":""},{"path":"https://davidhope.ca/BASSr/reference/create_sites.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create sampling sites within hexagons — create_sites","text":"","code":"create_sites(hexes, spacing = NULL, n = NULL, hex_id = hex_id)"},{"path":"https://davidhope.ca/BASSr/reference/create_sites.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create sampling sites within hexagons — create_sites","text":"hexes Spatial Data frame. Hexagon grid across sampling region. Requires column identifying hexagon IDs (see hex_id) spacing Numeric. Distance sites. Units assumed hex spatial data frame. n Numeric. Approximate number sites create within hex grid. hex_id Column. Identifies hexagon IDs (e.g., default hex_id).","code":""},{"path":"https://davidhope.ca/BASSr/reference/create_sites.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create sampling sites within hexagons — create_sites","text":"Spatial data frame sites points.","code":""},{"path":"https://davidhope.ca/BASSr/reference/create_sites.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create sampling sites within hexagons — create_sites","text":"","code":"# Get sites by exact within-hex distances sites_sp <- create_sites(psu_hexagons, spacing = 5)  # Get sites by approximate number of points (but equal spacing among hexes) sites_n <- create_sites(psu_hexagons, n = 61)  # Same number of sites, but in slightly different spots, because creating by # n maximizes spacing, but creating by spacing using the exact spacing # specified.  library(ggplot2) ggplot() +   geom_sf(data = psu_hexagons) +   geom_sf(data = sites_sp, size = 0.5, colour = \"red\") +   geom_sf(data = sites_n, size = 0.5, colour = \"blue\")"},{"path":"https://davidhope.ca/BASSr/reference/downweight_selection_pr.html","id":null,"dir":"Reference","previous_headings":"","what":"Adjust selection weighting — downweight_selection_pr","title":"Adjust selection weighting — downweight_selection_pr","text":"Adjust selection weighting","code":""},{"path":"https://davidhope.ca/BASSr/reference/downweight_selection_pr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adjust selection weighting — downweight_selection_pr","text":"","code":"downweight_selection_pr(   sample_locs,   scalingFactor,   sigma_value,   selection_column = NULL,   fun = \"cauchy\",   existing_sampling = NULL,   dmat = NULL )"},{"path":"https://davidhope.ca/BASSr/reference/downweight_selection_pr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adjust selection weighting — downweight_selection_pr","text":"sample_locs sf object selection weighting column (polygons points) scalingFactor scaling factor downweight sigma_value sigma value distribution effect existing sampling. Larger value means sampling wider effect selection_column Column sampling weights adjusted. null return weights. fun Type decay function. Current options 'cauchy', 'normal' 'exp' existing_sampling exisint sampling weight around (points) dmat distance matrix sample locations (rows) existing sampling (columns)","code":""},{"path":"https://davidhope.ca/BASSr/reference/downweight_selection_pr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adjust selection weighting — downweight_selection_pr","text":"data.frame sample_locs downweights adjusted selection probabilities included. selection column null return vector downweights alone.","code":""},{"path":"https://davidhope.ca/BASSr/reference/downweight_selection_pr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adjust selection weighting — downweight_selection_pr","text":"","code":"# downweight_selection_pr(BASSr::all_study_areas[1:10,], BASSr::all_study_areas[20:30,], scalingFactor = 0.1, sigma_value = 1e5, fun = 'cauchy', selection_column = NULL)"},{"path":"https://davidhope.ca/BASSr/reference/draw_random_samples.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw random sample — draw_random_samples","title":"Draw random sample — draw_random_samples","text":"Draw random sample","code":""},{"path":"https://davidhope.ca/BASSr/reference/draw_random_samples.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw random sample — draw_random_samples","text":"","code":"draw_random_samples(   land_hex,   num_runs,   n_samples,   use_grts = TRUE,   crs = 4326,   coords = c(\"lon\", \"lat\"),   return_grts = FALSE,   seed = NULL,   quiet = FALSE,   ... )"},{"path":"https://davidhope.ca/BASSr/reference/draw_random_samples.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw random sample — draw_random_samples","text":"land_hex (Spatial) Data frame. Land Cover data hexagon. non-spatial, converted spatial sf data frame using crs coords arguments. Requires columns identifying Hex ID well Stratum ID (see hex_id stratum_id respectively). num_runs Numeric. Number times draw random samples. n_samples Numeric. Number samples draw run. use_grts Logical. Whether use spsurvey::grts() just sample randomly without spatial dispersion. crs Numeric, character, sf/sfc. Coordinate reference system. Must valid input sf::st_crs(). coords Character vector. Names columns containing X Y coordinates (default c(\"lon\", \"lat\")). return_grts Logical. Return spsurvey object(s). seed Numeric. Random seed use random sampling. Seed applies specific sampling events (change seed environment). NULL set seed. quiet Logical. Whether suppress progress messages. ... Extra named arguments passed spsurvey::grts().","code":""},{"path":"https://davidhope.ca/BASSr/reference/draw_random_samples.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw random sample — draw_random_samples","text":"Spatial data frame samples","code":""},{"path":"https://davidhope.ca/BASSr/reference/draw_random_samples.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw random sample — draw_random_samples","text":"","code":"draw_random_samples(psu_hexagons, num_runs = 1, n_samples = 10) #> ℹ Spatial object land_hex should be POINTs not POLYGONs #> • Don't worry, I'll fix it! #> • Assuming constant attributes and using centroids as points #> ℹ Finished GRTS draw of 1 runs and 10 samples #> Simple feature collection with 10 features and 21 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 50 ymin: 43.30127 xmax: 275 ymax: 259.8076 #> Projected CRS: NAD83 / Ontario MNR Lambert #>       siteID siteuse replsite lon_WGS84 lat_WGS84 stratum wgt        ip caty #> 1  sample-01    Base     None -88.90970 -31.97499    None 3.3 0.3030303 None #> 2  sample-02    Base     None -88.90989 -31.97531    None 3.3 0.3030303 None #> 3  sample-03    Base     None -88.91044 -31.97487    None 3.3 0.3030303 None #> 4  sample-04    Base     None -88.91040 -31.97549    None 3.3 0.3030303 None #> 5  sample-05    Base     None -88.90966 -31.97561    None 3.3 0.3030303 None #> 6  sample-06    Base     None -88.91052 -31.97534    None 3.3 0.3030303 None #> 7  sample-07    Base     None -88.91012 -31.97501    None 3.3 0.3030303 None #> 8  sample-08    Base     None -88.91063 -31.97519    None 3.3 0.3030303 None #> 9  sample-09    Base     None -88.91008 -31.97563    None 3.3 0.3030303 None #> 10 sample-10    Base     None -88.91061 -31.97550    None 3.3 0.3030303 None #>    hex_id province water             LC1            LC2            LC3 #> 1   SA_51       ON  TRUE 201350.91 [m^2] 389711.4 [m^2] 569411.7 [m^2] #> 2   SA_42       ON FALSE 233826.86 [m^2] 326924.6 [m^2] 389711.4 [m^2] #> 3   SA_24       ON FALSE 255477.49 [m^2] 268467.9 [m^2] 478479.0 [m^2] #> 4   SA_22       ON FALSE 359400.54 [m^2] 171040.0 [m^2] 476314.0 [m^2] #> 5   SA_49       ON  TRUE 173205.08 [m^2] 201350.9 [m^2] 446003.1 [m^2] #> 6   SA_18       ON  TRUE 132068.87 [m^2] 467653.7 [m^2] 671169.7 [m^2] #> 7   SA_35       ON FALSE 246817.24 [m^2] 235991.9 [m^2] 506624.9 [m^2] #> 8   SA_15       ON  TRUE 177535.21 [m^2] 335584.8 [m^2] 686325.1 [m^2] #> 9   SA_33       ON FALSE 212176.22 [m^2] 300943.8 [m^2] 673334.8 [m^2] #> 10  SA_14       ON FALSE  19485.57 [m^2] 565081.6 [m^2] 710140.8 [m^2] #>                LC4             LC5           LC6             geometry run #> 1   887676.0 [m^2]  803238.6 [m^2] 2074131 [m^2] POINT (275 216.5064)   1 #> 2  1680089.3 [m^2]  664674.5 [m^2] 1688750 [m^2] POINT (225 129.9038)   1 #> 3   885511.0 [m^2] 1242746.5 [m^2] 1857624 [m^2] POINT (100 259.8076)   1 #> 4   904996.5 [m^2] 1115007.7 [m^2] 1961548 [m^2] POINT (100 86.60254)   1 #> 5   861695.3 [m^2] 1203775.3 [m^2] 2037325 [m^2] POINT (275 43.30127)   1 #> 6   926647.2 [m^2] 1054385.9 [m^2] 1732051 [m^2]  POINT (75 129.9038)   1 #> 7  1095522.1 [m^2] 1149648.7 [m^2] 1753701 [m^2] POINT (175 216.5064)   1 #> 8   911491.7 [m^2]  664674.5 [m^2] 2212695 [m^2]  POINT (50 173.2051)   1 #> 9   781587.9 [m^2]  959123.1 [m^2] 2061140 [m^2] POINT (175 43.30127)   1 #> 10  902831.5 [m^2]  772927.7 [m^2] 2017839 [m^2]  POINT (50 86.60254)   1 #>    num_runs n_samples #> 1         1        10 #> 2         1        10 #> 3         1        10 #> 4         1        10 #> 5         1        10 #> 6         1        10 #> 7         1        10 #> 8         1        10 #> 9         1        10 #> 10        1        10"},{"path":"https://davidhope.ca/BASSr/reference/estimate_cost_study_area.html","id":null,"dir":"Reference","previous_headings":"","what":"Cost model estimate — estimate_cost_study_area","title":"Cost model estimate — estimate_cost_study_area","text":"Cost model estimate","code":""},{"path":"https://davidhope.ca/BASSr/reference/estimate_cost_study_area.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cost model estimate — estimate_cost_study_area","text":"","code":"estimate_cost_study_area(   narus,   StudyAreas,   pr,   sr,   wr = 0,   dist_base_sa,   dist_airport_sa,   dist2airport_base,   AirportType,   vars )"},{"path":"https://davidhope.ca/BASSr/reference/estimate_cost_study_area.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cost model estimate — estimate_cost_study_area","text":"narus number ARUs deploy study area StudyAreas Tibble study area information distances pr Column primary road buffer proportion study area sr Column secondary Road proportion study area ( include primary road area) wr Column Winter Road proportion study area ( include primary secondary road areas) dist_base_sa Column distance basecamp study area dist_airport_sa Column distance airport study area dist2airport_base Column distance airport base camp AirportType Column nearest airport type vars List containing parameters cost estimation","code":""},{"path":"https://davidhope.ca/BASSr/reference/estimate_cost_study_area.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cost model estimate — estimate_cost_study_area","text":"data frame","code":""},{"path":"https://davidhope.ca/BASSr/reference/extract_habitat_cost-deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Habitat and Cost — extract_habitat_cost-deprecated","title":"Extract Habitat and Cost — extract_habitat_cost-deprecated","text":"Extract Habitat Cost","code":""},{"path":"https://davidhope.ca/BASSr/reference/extract_habitat_cost-deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Habitat and Cost — extract_habitat_cost-deprecated","text":"number_iterations Number iterations draw samples full GRTS n_samples_per_iter Number samples pull per iteration sample_hexes Sample hexagon file study_area_hexes Study area hexagon files id Id study area interest id_col Column identifying study area hab_rast_location Location raster habitat shape_file_list named list shapefiles used cost calculation. current iteration must include following names: primary_roads sf polygon primary roads buffer secondary_roads sf polygon atv roads buffer winter_roads sf polygon winter roads buffer total_roads sf polygon roads buffer airport_locations sf points airport locations camp_locations sf points camp locations return_all_ Logical return full results just inclusion probabilities nARUs number ARUs deploy hexid_col hexagon identification column calc_cost Logical - calculate cost calc_hab Logical - calculate habitat write_hexes Logical - write hexagons load_hexes Logical load hexagons rds.loc RDS location sa.rast.loc Study area location quick Run using cpp","code":""},{"path":"https://davidhope.ca/BASSr/reference/full_BASS_run.html","id":null,"dir":"Reference","previous_headings":"","what":"A full BASS run — full_BASS_run","title":"A full BASS run — full_BASS_run","text":"full BASS run","code":""},{"path":"https://davidhope.ca/BASSr/reference/full_BASS_run.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A full BASS run — full_BASS_run","text":"","code":"full_BASS_run(   land_hex,   num_runs,   n_samples,   costs = NULL,   hex_id = hex_id,   stratum_id = NULL,   omit_flag = NULL,   non_random_set = NULL,   benefit_weight = 0.5,   land_cover_weights = NULL,   return_grts = FALSE,   crs = 4326,   coords = c(\"lon\", \"lat\"),   seed = NULL,   quiet = FALSE,   ... )"},{"path":"https://davidhope.ca/BASSr/reference/full_BASS_run.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A full BASS run — full_BASS_run","text":"land_hex (Spatial) Data frame. Land Cover data hexagon. non-spatial, converted spatial sf data frame using crs coords arguments. Requires columns identifying Hex ID well Stratum ID (see hex_id stratum_id respectively). num_runs Numeric. Number times draw random samples. n_samples Numeric. Number samples draw run. costs Data frame. Costs hexagon RawCost format. hex_id Column. Identifies hexagon IDs (e.g., default hex_id). stratum_id Column. Identifies larger area (e.g., StudyAreaID Province). omit_flag Column identifying hexes omit (e.g., water hexes). non_random_set Character vector. hex_ids hexagons include non randomly selected set. benefit_weight Numeric. Weight assigned benefit selection probabilities. 0.5 equal weighting cost benefits. 1.0 zero weighting cost. Default 0.5. land_cover_weights Data frame. Proportional weights (weights column) specific types landcover (lc column). lc correspond landcover column names hex data. return_grts Logical. Return spsurvey object(s). crs Numeric, character, sf/sfc. Coordinate reference system. Must valid input sf::st_crs(). coords Character vector. Names columns containing X Y coordinates (default c(\"lon\", \"lat\")). seed Numeric. Random seed use random sampling. Seed applies specific sampling events (change seed environment). NULL set seed. quiet Logical. Whether suppress progress messages. ... Extra named arguments passed spsurvey::grts().","code":""},{"path":"https://davidhope.ca/BASSr/reference/full_BASS_run.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A full BASS run — full_BASS_run","text":"Data frame inclusion probabilities. , return_grts = TRUE list including data frame inclusion probabilities well spsurvey grts sampling object.","code":""},{"path":"https://davidhope.ca/BASSr/reference/full_BASS_run.html","id":"extra-arguments","dir":"Reference","previous_headings":"","what":"Extra arguments","title":"A full BASS run — full_BASS_run","text":"Extra named arguments spsurvey::grts() can also passed via .... particular, note default values mindis (minimum distance sites) NULL, maxtry (maximum attempts try obtain minimum distance sites) 10.","code":""},{"path":"https://davidhope.ca/BASSr/reference/full_BASS_run.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A full BASS run — full_BASS_run","text":"","code":"# With example data psu_hexagons and psu_costs...  d <- full_BASS_run(   land_hex = psu_hexagons,   num_runs = 10,   n_samples = 3,   costs = psu_costs) #> ℹ Spatial object land_hex should be POINTs not POLYGONs #> • Don't worry, I'll fix it! #> • Assuming constant attributes and using centroids as points #> ℹ Finished GRTS draw of 10 runs and 3 samples  # Omit water hexes  d <- full_BASS_run(   land_hex = psu_hexagons,   num_runs = 10,   n_samples = 3,   costs = psu_costs,   omit_flag = water) #> ℹ Spatial object land_hex should be POINTs not POLYGONs #> • Don't worry, I'll fix it! #> • Assuming constant attributes and using centroids as points #> ℹ Finished GRTS draw of 10 runs and 3 samples  # Keep grts objects  d <- full_BASS_run(   land_hex = psu_hexagons,   num_runs = 10,   n_samples = 3,   costs = psu_costs,   return_grts = TRUE) #> ℹ Spatial object land_hex should be POINTs not POLYGONs #> • Don't worry, I'll fix it! #> • Assuming constant attributes and using centroids as points #> ℹ Finished GRTS draw of 10 runs and 3 samples  names(d) #> [1] \"inclusion_probs\" \"grts_output\"     d[[\"inclusion_probs\"]] #> Simple feature collection with 33 features and 11 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 25 ymin: 43.30127 xmax: 275 ymax: 259.8076 #> Projected CRS: NAD83 / Ontario MNR Lambert #> # A tibble: 33 × 12 #>    hex_id  RawCost benefit       geometry LogCost ScLogCost scale_ben #>  * <glue>    <dbl>   <dbl>    <POINT [m]>   <dbl>     <dbl>     <dbl> #>  1 SA_09    1.73e9  0.0307  (25 43.30127)    9.24     0.888     0.513 #>  2 SA_10    1.59e9  0.0356  (25 129.9038)    9.20     0.885     0.594 #>  3 SA_11    1.77e9  0.0323  (25 216.5064)    9.25     0.889     0.538 #>  4 SA_14    1.67e9  0.0297  (50 86.60254)    9.22     0.887     0.495 #>  5 SA_15    1.52e9  0.0221  (50 173.2051)    9.18     0.883     0.369 #>  6 SA_16    2.00e9  0.0274  (50 259.8076)    9.30     0.894     0.458 #>  7 SA_17    2.18e9  0.0259  (75 43.30127)    9.34     0.898     0.431 #>  8 SA_18    2.24e9  0.0367  (75 129.9038)    9.35     0.899     0.613 #>  9 SA_19    1.69e9  0.0289  (75 216.5064)    9.23     0.887     0.482 #> 10 SA_22    1.71e9  0.0374 (100 86.60254)    9.23     0.888     0.623 #> # ℹ 23 more rows #> # ℹ 5 more variables: partIP <dbl>, weightedIP <dbl>, inclpr <dbl>, #> #   num_runs <dbl>, n_samples <dbl> d[[\"grts_output\"]][[1]] #> Summary of Site Counts:  #>  #>    total   siteuse  #>  total:3   Base:3    # Change spsurvey::grts() arguments  d <- full_BASS_run(   land_hex = psu_hexagons,   num_runs = 10,   n_samples = 3,   costs = psu_costs,   mindis = 10, maxtry = 10) #> ℹ Spatial object land_hex should be POINTs not POLYGONs #> • Don't worry, I'll fix it! #> • Assuming constant attributes and using centroids as points #> ℹ Finished GRTS draw of 10 runs and 3 samples  d #> Simple feature collection with 33 features and 11 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 25 ymin: 43.30127 xmax: 275 ymax: 259.8076 #> Projected CRS: NAD83 / Ontario MNR Lambert #> # A tibble: 33 × 12 #>    hex_id  RawCost benefit       geometry LogCost ScLogCost scale_ben #>  * <glue>    <dbl>   <dbl>    <POINT [m]>   <dbl>     <dbl>     <dbl> #>  1 SA_09    1.73e9  0.0298  (25 43.30127)    9.24     0.888     0.535 #>  2 SA_10    1.59e9  0.0321  (25 129.9038)    9.20     0.885     0.575 #>  3 SA_11    1.77e9  0.0304  (25 216.5064)    9.25     0.889     0.544 #>  4 SA_14    1.67e9  0.0307  (50 86.60254)    9.22     0.887     0.550 #>  5 SA_15    1.52e9  0.0266  (50 173.2051)    9.18     0.883     0.477 #>  6 SA_16    2.00e9  0.0351  (50 259.8076)    9.30     0.894     0.630 #>  7 SA_17    2.18e9  0.0303  (75 43.30127)    9.34     0.898     0.543 #>  8 SA_18    2.24e9  0.0368  (75 129.9038)    9.35     0.899     0.659 #>  9 SA_19    1.69e9  0.0275  (75 216.5064)    9.23     0.887     0.493 #> 10 SA_22    1.71e9  0.0373 (100 86.60254)    9.23     0.888     0.669 #> # ℹ 23 more rows #> # ℹ 5 more variables: partIP <dbl>, weightedIP <dbl>, inclpr <dbl>, #> #   num_runs <dbl>, n_samples <dbl>"},{"path":"https://davidhope.ca/BASSr/reference/genraster-deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Raster — genraster-deprecated","title":"Generate Raster — genraster-deprecated","text":"Generate Raster","code":""},{"path":"https://davidhope.ca/BASSr/reference/genraster-deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Raster — genraster-deprecated","text":"id_col Column use studyareas Study area list id Id study area extract hab_rast_location Location habitat file writeout Logical - write output outpath Location output","code":""},{"path":"https://davidhope.ca/BASSr/reference/getresults_BASS-deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the results from a BASS grts run — getresults_BASS-deprecated","title":"Get the results from a BASS grts run — getresults_BASS-deprecated","text":"Get results BASS grts run","code":""},{"path":"https://davidhope.ca/BASSr/reference/getresults_BASS-deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the results from a BASS grts run — getresults_BASS-deprecated","text":"grts_output Hypothetical sample set study_area_results Study area results BASS nARUs Number ARUs deploy","code":""},{"path":"https://davidhope.ca/BASSr/reference/lcc2015_codes.html","id":null,"dir":"Reference","previous_headings":"","what":"2015 National Landcover Classification Table — lcc2015_codes","title":"2015 National Landcover Classification Table — lcc2015_codes","text":"Key land cover codes names","code":""},{"path":"https://davidhope.ca/BASSr/reference/lcc2015_codes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"2015 National Landcover Classification Table — lcc2015_codes","text":"","code":"lcc2015_codes"},{"path":"https://davidhope.ca/BASSr/reference/lcc2015_codes.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"2015 National Landcover Classification Table — lcc2015_codes","text":"data frame 19 rows 2 variables: LCC_CODE Land cover code LCC_NAME Land cover name","code":""},{"path":"https://davidhope.ca/BASSr/reference/lcc2015_codes.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"2015 National Landcover Classification Table — lcc2015_codes","text":"https://open.canada.ca/data/en/dataset/4e615eae-b90c-420b-adee-2ca35896caf6","code":""},{"path":"https://davidhope.ca/BASSr/reference/noGRTS_BASS_run-deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"A calculate BASS from random samples — noGRTS_BASS_run-deprecated","title":"A calculate BASS from random samples — noGRTS_BASS_run-deprecated","text":"calculate BASS random samples","code":""},{"path":"https://davidhope.ca/BASSr/reference/noGRTS_BASS_run-deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A calculate BASS from random samples — noGRTS_BASS_run-deprecated","text":"samples Hypothetical sample set num_runs number times draw random samples hexagons n_samples number samples draw sample costs cost table hexagon id","code":""},{"path":"https://davidhope.ca/BASSr/reference/ontario.html","id":null,"dir":"Reference","previous_headings":"","what":"Polygon SF of Ontario — ontario","title":"Polygon SF of Ontario — ontario","text":"poloygon outline Ontario","code":""},{"path":"https://davidhope.ca/BASSr/reference/ontario.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Polygon SF of Ontario — ontario","text":"","code":"ontario"},{"path":"https://davidhope.ca/BASSr/reference/ontario.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Polygon SF of Ontario — ontario","text":"simple feature data frame 1 rows 2 variables: PROV Two letter code Ontario NAME Name Province geometry SF geometry","code":""},{"path":"https://davidhope.ca/BASSr/reference/ontario.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Polygon SF of Ontario — ontario","text":"Map Canadian Jurisdictions","code":""},{"path":"https://davidhope.ca/BASSr/reference/oppositeSigns.html","id":null,"dir":"Reference","previous_headings":"","what":"Opposite signs True or false — oppositeSigns","title":"Opposite signs True or false — oppositeSigns","text":"Opposite signs True false","code":""},{"path":"https://davidhope.ca/BASSr/reference/oppositeSigns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Opposite signs True or false — oppositeSigns","text":"","code":"oppositeSigns(x, y)"},{"path":"https://davidhope.ca/BASSr/reference/oppositeSigns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Opposite signs True or false — oppositeSigns","text":"x double value y integer","code":""},{"path":"https://davidhope.ca/BASSr/reference/prepare_cost.html","id":null,"dir":"Reference","previous_headings":"","what":"Propare hexagons for cost calculations — prepare_cost","title":"Propare hexagons for cost calculations — prepare_cost","text":"Propare hexagons cost calculations","code":""},{"path":"https://davidhope.ca/BASSr/reference/prepare_cost.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Propare hexagons for cost calculations — prepare_cost","text":"","code":"prepare_cost(   truck_roads,   atv_roads,   winter_roads,   all_roads,   airports,   basecamps,   hexagons,   idcol_,   calc_roads = T,   airport_cols = c(\"NAME\", \"AIRPORT_TY\", \"OGF_ID\"),   basecamp_cols = c(\"OFFICIAL_N\", \"OGF_ID\", \"CLASS_SUBT\"),   ... )"},{"path":"https://davidhope.ca/BASSr/reference/prepare_cost.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Propare hexagons for cost calculations — prepare_cost","text":"truck_roads Primary roads (truck roads) buffer. polygon layer. used calculating road estimates. atv_roads Secondary (atv roads) buffer. polygon layer. used calculating road estimates. winter_roads Winter roads buffer. polygon layer. currently use. all_roads Total roads buffer. polygon.  currently use. airports Airport locations. polygon layer. basecamps Basecamp locations. polygon layer. hexagons Hexagon layer idcol_ Column hexagon ids calc_roads Logical. calculate roads already included hexagon layer airport_cols Columns use extract airport info. See examples. length 3. basecamp_cols Columns use extract basecamp info. See examples. length 3. ... can include multisession furrr package. Needs include Multicor=T & Cores = int","code":""},{"path":"https://davidhope.ca/BASSr/reference/prepare_cost.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Propare hexagons for cost calculations — prepare_cost","text":"data frame","code":""},{"path":"https://davidhope.ca/BASSr/reference/prepare_cost.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Propare hexagons for cost calculations — prepare_cost","text":"","code":"if (FALSE) { # \\dontrun{ prepare_cost(   truck_roads = NA, atv_roads = NA, winter_roads = NA, all_roads = NA, airports = airports_official, basecamps = tourism, hexagons = study_area_hexagons_in_brandt %>%     sf::left_join(road_info, by = c(\"StudyAreaID\" = \"StudyArea\")), idcol_ = StudyAreaID, calc_roads = F, airport_cols = c(\"NAME\", \"AIRPORT_TY\", \"OGF_ID\"),   basecamp_cols = c(\"OFFICIAL_N\", \"OGF_ID\", \"CLASS_SUBT\") ) } # }"},{"path":"https://davidhope.ca/BASSr/reference/psu_costs.html","id":null,"dir":"Reference","previous_headings":"","what":"Dummy costs data — psu_costs","title":"Dummy costs data — psu_costs","text":"Dummy costs data","code":""},{"path":"https://davidhope.ca/BASSr/reference/psu_costs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dummy costs data — psu_costs","text":"","code":"psu_costs"},{"path":"https://davidhope.ca/BASSr/reference/psu_costs.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dummy costs data — psu_costs","text":"data frame 33 rows 27 columns hex_id ID hex province Province code hex water Whether hex water area Area hex m2 pr - total_heli_cost Specific costs hex (see ?estimate_cost_study_area) narus Number ARUs deployed RawCost Total raw cost sampling hex","code":""},{"path":"https://davidhope.ca/BASSr/reference/psu_costs.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Dummy costs data — psu_costs","text":"Data generated data-raw/data_create_study_area.R","code":""},{"path":"https://davidhope.ca/BASSr/reference/psu_hex_dirty.html","id":null,"dir":"Reference","previous_headings":"","what":"Dummy hex data to be cleaned — psu_hex_dirty","title":"Dummy hex data to be cleaned — psu_hex_dirty","text":"Dummy hex data cleaned","code":""},{"path":"https://davidhope.ca/BASSr/reference/psu_hex_dirty.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dummy hex data to be cleaned — psu_hex_dirty","text":"","code":"psu_hex_dirty"},{"path":"https://davidhope.ca/BASSr/reference/psu_hex_dirty.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dummy hex data to be cleaned — psu_hex_dirty","text":"spatial data frame 33 features 9 fields hex_id ID hex province Province code hex water Whether hex water CLC... Land cover columns x Geometry","code":""},{"path":"https://davidhope.ca/BASSr/reference/psu_hex_dirty.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Dummy hex data to be cleaned — psu_hex_dirty","text":"Data generated data-raw/data_create_study_area.R","code":""},{"path":"https://davidhope.ca/BASSr/reference/psu_hexagons.html","id":null,"dir":"Reference","previous_headings":"","what":"Dummy hex data — psu_hexagons","title":"Dummy hex data — psu_hexagons","text":"Dummy hex data","code":""},{"path":"https://davidhope.ca/BASSr/reference/psu_hexagons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dummy hex data — psu_hexagons","text":"","code":"psu_hexagons"},{"path":"https://davidhope.ca/BASSr/reference/psu_hexagons.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dummy hex data — psu_hexagons","text":"spatial data frame 33 features 9 fields hex_id ID hex province Province code hex water Whether hex water LC... Land cover columns x Geometry","code":""},{"path":"https://davidhope.ca/BASSr/reference/psu_hexagons.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Dummy hex data — psu_hexagons","text":"Data generated data-raw/data_create_study_area.R","code":""},{"path":"https://davidhope.ca/BASSr/reference/psu_samples.html","id":null,"dir":"Reference","previous_headings":"","what":"Dummy sampled hexes — psu_samples","title":"Dummy sampled hexes — psu_samples","text":"Dummy sampled hexes","code":""},{"path":"https://davidhope.ca/BASSr/reference/psu_samples.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dummy sampled hexes — psu_samples","text":"","code":"psu_samples"},{"path":"https://davidhope.ca/BASSr/reference/psu_samples.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dummy sampled hexes — psu_samples","text":"spatial data frame 30 features 21 fields siteID-caty Sampling output (see spsurvey::grts()) hex_id ID hex province Province code hex water Whether hex water LC... Land cover columns x Geometry run Run number num_runs Total number runs performed n_samples Total number samples drawn run","code":""},{"path":"https://davidhope.ca/BASSr/reference/psu_samples.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Dummy sampled hexes — psu_samples","text":"Data generated data-raw/data_create_study_area.R","code":""},{"path":"https://davidhope.ca/BASSr/reference/run_full_BASS_w_selection-defunct.html","id":null,"dir":"Reference","previous_headings":"","what":"Full BASSr run with sample selection — run_full_BASS_w_selection-defunct","title":"Full BASSr run with sample selection — run_full_BASS_w_selection-defunct","text":"Running function run BASS study areas sample units within study areas. return selection sample units associated costs habitats.","code":""},{"path":"https://davidhope.ca/BASSr/reference/run_full_BASS_w_selection-defunct.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Full BASSr run with sample selection — run_full_BASS_w_selection-defunct","text":"study_areas_hab_cost list study area hexagons, costs, habitat characteristics. See naming . Number_of_Study_areas Number Study Areas select Number_of_sample_units Number Sample Units select Size_of_HSS Size Hypothetical Sample Set Number_of_HSS Number iterations hypothetical sample set Weight_of_benfit Weight benefit selection probabilties. LandCoverType String identifer land cover hexagons code within tibble RemovedLayers_ Layers remove benefit calculation must format c(-var1, -var2, -var3) Area_of_interest Area interest tibble StudyAreaID RandomSeed Random seet use GRTS calculate_benefits calculate benefits included benefit_df only_calculate_benefits want calculate benefits complete full run benefit_dfs calculate_benefits TRUE need data.frames benefits. returnALL return GRTS object, well selection probs. (Can used later calculate spatial balance) oversample Proportion sites oversample, used study areas sample units weighted_benefits_df list data frames weight land covers benefit calculation Non random set study areas sample units form named list.","code":""},{"path":"https://davidhope.ca/BASSr/reference/run_full_BASS_w_selection-defunct.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Full BASSr run with sample selection — run_full_BASS_w_selection-defunct","text":"List sample units summary comparing land cover local area","code":""},{"path":"https://davidhope.ca/BASSr/reference/run_grts_on_BASS.html","id":null,"dir":"Reference","previous_headings":"","what":"Run grts sampling on BASSr results — run_grts_on_BASS","title":"Run grts sampling on BASSr results — run_grts_on_BASS","text":"Sample sites based cost/benefit probabilities calculated previous steps. Sites can sampled without stratification.","code":""},{"path":"https://davidhope.ca/BASSr/reference/run_grts_on_BASS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run grts sampling on BASSr results — run_grts_on_BASS","text":"","code":"run_grts_on_BASS(   probs,   nARUs,   os = NULL,   num_runs = 1,   hex_id = NULL,   stratum_id = NULL,   remove_hexes = NULL,   selection_weighting = inclpr,   seed = NULL,   ... )"},{"path":"https://davidhope.ca/BASSr/reference/run_grts_on_BASS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run grts sampling on BASSr results — run_grts_on_BASS","text":"probs Data frame. Output calculate_inclusion_probs() full_BASS_run(). nARUs Numeric, Data frame, Vector, List. Number base samples choose. stratification, named vector/list samples per stratum, data frame columns n samples, n_os oversamples column matching stratum_id. os Numeric, Vector, List. sample size (proportional) named vector/list number samples per stratum. Ignored nARUs data frame. num_runs Numeric. Number times draw random samples. hex_id Column. Identifies hexagon IDs (e.g., default hex_id). stratum_id Column. Identifies larger area (e.g., StudyAreaID Province). remove_hexes Character Vector. Ids hexagons remove prior sampling. selection_weighting Column. Identifies selection weightings used aux_var argument spsurvey::grts(). Default inclpr. seed Numeric. Random seed use random sampling. Seed applies specific sampling events (change seed environment). NULL set seed. ... Extra named arguments passed spsurvey::grts().","code":""},{"path":"https://davidhope.ca/BASSr/reference/run_grts_on_BASS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run grts sampling on BASSr results — run_grts_on_BASS","text":"num_runs 1, single spsurvey object, otherwise list spsurvey objects.","code":""},{"path":"https://davidhope.ca/BASSr/reference/run_grts_on_BASS.html","id":"extra-arguments","dir":"Reference","previous_headings":"","what":"Extra arguments","title":"Run grts sampling on BASSr results — run_grts_on_BASS","text":"Extra named arguments spsurvey::grts() can also passed via .... particular, note default values mindis (minimum distance sites) NULL, maxtry (maximum attempts try obtain minimum distance sites) 10.","code":""},{"path":"https://davidhope.ca/BASSr/reference/run_grts_on_BASS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run grts sampling on BASSr results — run_grts_on_BASS","text":"","code":"d <- full_BASS_run(   land_hex = psu_hexagons,   num_runs = 10,   n_samples = 3,   costs = psu_costs) #> ℹ Spatial object land_hex should be POINTs not POLYGONs #> • Don't worry, I'll fix it! #> • Assuming constant attributes and using centroids as points #> ℹ Finished GRTS draw of 10 runs and 3 samples  # Simple selection sel <- run_grts_on_BASS(   probs = d,   nARUs = 5,   os = 0.2)  # Stratify d <- dplyr::mutate(d, Province = c(rep(\"ON\", 16), rep(\"MB\", 17))) # Add Strata  # With lists... sel <- run_grts_on_BASS(   probs = d,   nARUs = list(\"ON\" = 5, \"MB\" = 2),   stratum_id = Province,   os = 0.2)  # With data frame... sel <- run_grts_on_BASS(   probs = d,   nARUs = data.frame(Province = c(\"ON\", \"MB\"),                      n = c(5, 2),                      n_os = c(1, 1)),   stratum_id = Province)"},{"path":"https://davidhope.ca/BASSr/reference/select_sites.html","id":null,"dir":"Reference","previous_headings":"","what":"Select sites for sampling — select_sites","title":"Select sites for sampling — select_sites","text":"Selection methods processing site selection using GRTS, random sampling, clustering, shortest path methods.","code":""},{"path":"https://davidhope.ca/BASSr/reference/select_sites.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select sites for sampling — select_sites","text":"","code":"select_sites(   sites,   type,   n_samples,   min_dist,   cluster_size = NULL,   min_dist_cluster = NULL,   os = NULL,   hex_id = hex_id,   site_id = site_id,   ARUonly = FALSE,   useGRTS = TRUE,   progress = TRUE,   seed = NULL )"},{"path":"https://davidhope.ca/BASSr/reference/select_sites.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select sites for sampling — select_sites","text":"sites Spatial Data frame. Site points created create_sites(). Requires columns identifying Hex ID well Site ID (see hex_id site_id respectively). type String. Method select sites. Must one \"cluster\" - Clustered sampling. Sample single point, cluster_size samples around point. \"path\" - Shortest Path sampling. Sample single point, cluster_size samples path point. \"Random\" - Random sampling. Sample random set points. n_samples Numeric. Number samples draw hex. min_dist Numeric. Minimum distance points, Clusters, cluster centres. cluster_size Integer. Clusters, number points per cluster. Shortest Paths, number points per path. applies Clusters Paths. min_dist_cluster Numeric. Minimum distance ARU samples within clusters. applies Clusters. os Numeric. sample size (proportional). applies Clusters Random. hex_id Column. Identifies hexagon IDs (e.g., default hex_id). site_id Column. Identifies site IDs (default site_id). ARUonly Logical. Return ARU locations. FALSE Clusters return point count locations well. applies Clusters Random sampling. useGRTS Logical. program run using GRTS? applies Clusters Random samples. progress Logical. Show progress bars applicable. seed Numeric. Random seed use random sampling. Seed applies specific sampling events (change seed environment). NULL set seed.","code":""},{"path":"https://davidhope.ca/BASSr/reference/select_sites.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select sites for sampling — select_sites","text":"Clustered, returns data frame clustered points selected sites. Random, returns data frame sampled points selected sites. Shortest Path, returns list points path original points selected create path.","code":""},{"path":"https://davidhope.ca/BASSr/reference/select_sites.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select sites for sampling — select_sites","text":"","code":"library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union library(ggplot2)  sites <- psu_hexagons |>     slice_sample(n = 7) |>     create_sites(spacing = 5) |>     mutate(scaled_benefit = 1, benefit = 0.95)  # Basic clusters s <- select_sites(sites = sites, hex_id = hex_id, site_id = site_id,                   type = \"cluster\", os = 0.75, n_samples = 7, cluster_size = 5,                   ARUonly = FALSE, seed = 1234, useGRTS = TRUE,                   min_dist = 25, min_dist_cluster = 9) #> projected points #> projected points #> projected points #> projected points #> projected points #> projected points #> projected points ggplot() +   geom_sf(data = psu_hexagons) +                   # Hex grid   geom_sf(data = sites, alpha = 0.4) +      # Sites on selected Hex grids   geom_sf(data = s, aes(colour = aru)) + # Selected sites   scale_colour_viridis_d()   # Random samples  s <- select_sites(sites = sites, hex_id = hex_id, site_id = site_id,                   type = \"random\", os = 1.0, n_samples = 2,                   ARUonly = FALSE, seed = 1234, min_dist = 10)  ggplot() +   geom_sf(data = psu_hexagons) +                   # Hex grid   geom_sf(data = sites, alpha = 0.4) +      # Sites on selected Hex grids   geom_sf(data = s, aes(colour = siteuse)) + # Selected sites   scale_colour_viridis_d()   # Shortest Path  s <- select_sites(sites = sites, hex_id = hex_id, site_id = site_id,                   type = \"path\", n_samples = 8, cluster_size = 4,                   ARUonly = FALSE, seed = 1234, useGRTS = TRUE,                   min_dist = 10, progress = FALSE)  ggplot() +   geom_sf(data = sites, alpha = 0.4) + # Sites on selected Hex grid   geom_sf(data = s$routes, aes(colour = factor(route))) + # Selected sites   scale_colour_viridis_d()"},{"path":"https://davidhope.ca/BASSr/reference/speedbass.html","id":null,"dir":"Reference","previous_headings":"","what":"The internal BASSr benefit algorithm — speedbass","title":"The internal BASSr benefit algorithm — speedbass","text":"internal BASSr benefit algorithm","code":""},{"path":"https://davidhope.ca/BASSr/reference/speedbass.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The internal BASSr benefit algorithm — speedbass","text":"","code":"speedbass(hex, w, sample, total, printDets = FALSE)"},{"path":"https://davidhope.ca/BASSr/reference/speedbass.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The internal BASSr benefit algorithm — speedbass","text":"hex vector land cover values w vector weights land cover value sample vector land cover values random sample total vector land cover values total study area printDets logical - print details - messy now.","code":""},{"path":"https://davidhope.ca/BASSr/reference/ssu_land_cover.html","id":null,"dir":"Reference","previous_headings":"","what":"Dummy SSU land cover — ssu_land_cover","title":"Dummy SSU land cover — ssu_land_cover","text":"Dummy SSU land cover","code":""},{"path":"https://davidhope.ca/BASSr/reference/ssu_land_cover.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dummy SSU land cover — ssu_land_cover","text":"","code":"ssu_land_cover"},{"path":"https://davidhope.ca/BASSr/reference/ssu_land_cover.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dummy SSU land cover — ssu_land_cover","text":"data frame 3003 rows 10 columns hex_id ID hex ssuID ID subsampling unit (hex) HexArea Area SSU hex LC... Land cover columns province Province code hex","code":""},{"path":"https://davidhope.ca/BASSr/reference/ssu_land_cover.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Dummy SSU land cover — ssu_land_cover","text":"Data generated data-raw/data_create_study_area.R","code":""},{"path":"https://davidhope.ca/BASSr/reference/ssu_points.html","id":null,"dir":"Reference","previous_headings":"","what":"Dummy SSU points — ssu_points","title":"Dummy SSU points — ssu_points","text":"Dummy SSU points","code":""},{"path":"https://davidhope.ca/BASSr/reference/ssu_points.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dummy SSU points — ssu_points","text":"","code":"ssu_points"},{"path":"https://davidhope.ca/BASSr/reference/ssu_points.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dummy SSU points — ssu_points","text":"spatial data frame 3003 features 3 fields geometry Geometry hex_id ID hex ssuID ID subsampling unit (hex) province Province code hex","code":""},{"path":"https://davidhope.ca/BASSr/reference/ssu_points.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Dummy SSU points — ssu_points","text":"Data generated data-raw/data_create_study_area.R","code":""},{"path":"https://davidhope.ca/BASSr/reference/subsample_grts_and_calc_benefit-deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"Subsample GRTS and calculate benefit — subsample_grts_and_calc_benefit-deprecated","title":"Subsample GRTS and calculate benefit — subsample_grts_and_calc_benefit-deprecated","text":"Subsample GRTS calculate benefit","code":""},{"path":"https://davidhope.ca/BASSr/reference/subsample_grts_and_calc_benefit-deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subsample GRTS and calculate benefit — subsample_grts_and_calc_benefit-deprecated","text":"n_samples Number Samples num_runs Number iterations grts_file grts file run land_hex Att frame quick run using CPP quick calc","code":""},{"path":"https://davidhope.ca/BASSr/reference/sumC.html","id":null,"dir":"Reference","previous_headings":"","what":"sum of vector — sumC","title":"sum of vector — sumC","text":"sum vector","code":""},{"path":"https://davidhope.ca/BASSr/reference/sumC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"sum of vector — sumC","text":"","code":"sumC(x)"},{"path":"https://davidhope.ca/BASSr/reference/sumC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"sum of vector — sumC","text":"x vector","code":""},{"path":"https://davidhope.ca/BASSr/reference/sumH.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a number to a sum of vector — sumH","title":"Add a number to a sum of vector — sumH","text":"Add number sum vector","code":""},{"path":"https://davidhope.ca/BASSr/reference/sumH.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add a number to a sum of vector — sumH","text":"","code":"sumH(x, h)"},{"path":"https://davidhope.ca/BASSr/reference/sumH.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a number to a sum of vector — sumH","text":"x vector h nuber add","code":""}]
